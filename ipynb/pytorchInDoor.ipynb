{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "import torch\n",
    "x = torch.tensor([[5.5,3],[1,2],[5,0]])\n",
    "print(x)\n",
    "y = torch.randn_like(x,dtype=torch.float)\n",
    "print(y)\n",
    "print(x+y,y.size())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[5.5000, 3.0000],\n",
      "        [1.0000, 2.0000],\n",
      "        [5.0000, 0.0000]])\n",
      "tensor([[ 0.7544, -0.9401],\n",
      "        [ 0.1931,  1.5394],\n",
      "        [-1.3066, -0.5627]])\n",
      "tensor([[ 6.2544,  2.0599],\n",
      "        [ 1.1931,  3.5394],\n",
      "        [ 3.6934, -0.5627]]) torch.Size([3, 2])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# 如果将其属性 .requires_grad 设置为 True，则会开始跟踪针对 tensor 的所有操作\n",
    "x = torch.ones(3, 2, requires_grad=True)\n",
    "# print(x)\n",
    "y = x + 2\n",
    "# print(y,y.grad_fn)\n",
    "\n",
    "z = y*y*3\n",
    "out = z.mean()\n",
    "print(z, out)\n",
    "out.backward()\n",
    "print(x.grad)\n",
    "\n",
    "# a = torch.randn(2, 2)\n",
    "# a = ((a * 3) / (a - 1))\n",
    "# print(a.requires_grad)\n",
    "# a.requires_grad_(True)\n",
    "# print(a.requires_grad)\n",
    "# b = (a * a).sum()\n",
    "# print(b,b.grad_fn)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.],\n",
      "        [3., 3.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "print(x)\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "  print(y.data.norm())\n",
    "  y = y * 2\n",
    "print(y)\n",
    "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(v)\n",
    "\n",
    "print(x.grad)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([-0.4303,  1.1554,  1.2227], requires_grad=True)\n",
      "tensor(3.4728)\n",
      "tensor(6.9456)\n",
      "tensor(13.8912)\n",
      "tensor(27.7824)\n",
      "tensor(55.5648)\n",
      "tensor(111.1296)\n",
      "tensor(222.2592)\n",
      "tensor(444.5183)\n",
      "tensor(889.0367)\n",
      "tensor([-440.6380, 1183.1306, 1252.0323], grad_fn=<MulBackward0>)\n",
      "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "# 神经网络\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "  \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "input = torch.randn(1,1,32,32)\n",
    "out = net(input)\n",
    "print(out)\n",
    "# print(input,input.size)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-0.0414, -0.0734, -0.1011,  0.0233, -0.1059,  0.0061, -0.1027, -0.0664,\n",
      "         -0.1070, -0.0773]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)\n",
    "target = target.view(1,-1)# make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "print(output,target)\n",
    "loss = criterion(output,target)\n",
    "print(loss)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-0.0414, -0.0734, -0.1011,  0.0233, -0.1059,  0.0061, -0.1027, -0.0664,\n",
      "         -0.1070, -0.0773]], grad_fn=<AddmmBackward>) tensor([[ 1.6366, -0.4556, -0.1748, -0.3339, -0.5980, -2.2791, -0.2987, -1.1109,\n",
      "          1.0826, -0.3172]])\n",
      "tensor(1.1161, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('lxj': conda)"
  },
  "interpreter": {
   "hash": "b64bdcc994c8f7d949a2d83a13fc595dca964918da548cf18f02209088b94299"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}