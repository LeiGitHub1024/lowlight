{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.util import random_noise\n",
    "import torch\n",
    "import torch.utils.data as Data \n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def mbllen_loader(device):\n",
    "    # image => npy\n",
    "    # mbllenPath = './data/mbllen'\n",
    "    # mbllenLowPath = './data/mbllen_lowlight'\n",
    "    # train = []\n",
    "    # train_lowlight = []\n",
    "    # i=5000\n",
    "    # for file in tqdm(os.listdir(mbllenPath)):\n",
    "    #     if(i==0):\n",
    "    #         break\n",
    "    #     i =i-1\n",
    "    #     train_path = os.path.join(mbllenPath, file)\n",
    "    #     if os.path.isfile(train_path) == True:\n",
    "    #         im = np.array(Image.open(train_path))\n",
    "    #         train.append(im)\n",
    "    #     lowlight_path = os.path.join(mbllenLowPath, file)\n",
    "    #     if os.path.isfile(lowlight_path) == True:\n",
    "    #         im = np.array(Image.open(lowlight_path))\n",
    "    #         train_lowlight.append(im)\n",
    "    # np.save(\"./data/mb_train.npy\", train) \n",
    "    # np.save(\"./data/mb_train_lowlight.npy\", train_lowlight) \n",
    "\n",
    "    #load npy\n",
    "    image_train = np.load('./data/mb_train.npy')\n",
    "    image_train = np.reshape(image_train, [-1, 3, 256, 256])\n",
    "    image_train = np.transpose(image_train, [0, 3, 2, 1])\n",
    "\n",
    "    image_lowlight = np.load('./data/mb_train_lowlight.npy') \n",
    "    image_lowlight = np.reshape(image_lowlight, [-1, 3, 256, 256])   \n",
    "    image_lowlight = np.transpose(image_lowlight, [0, 3, 2, 1])\n",
    "    return image_train/255, image_lowlight/255\n",
    "\n",
    "train,train_lowlight = mbllen_loader(device)\n",
    "\n",
    "train.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5000, 256, 256, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# 数据集准备为PyTorch可用的形式，转化为[样本, 通道, 高, 宽]\n",
    "data_X = np.transpose(train, (0, 3, 2, 1))\n",
    "data_Y = np.transpose(train_lowlight, (0, 3, 2, 1))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(data_X, data_Y, test_size=0.2, random_state=123)\n",
    "# 转化为torch张量\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
    "# 将X与y整合在一起\n",
    "train_data = Data.TensorDataset(X_train, y_train)\n",
    "val_data = Data.TensorDataset(X_val, y_val)\n",
    "\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"X_val.shape:\", X_val.shape)\n",
    "print(\"y_val.shape:\", y_val.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_train.shape torch.Size([4000, 3, 256, 256])\n",
      "y_train.shape: torch.Size([4000, 3, 256, 256])\n",
      "X_val.shape: torch.Size([1000, 3, 256, 256])\n",
      "y_val.shape: torch.Size([1000, 3, 256, 256])\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('lxj': conda)"
  },
  "interpreter": {
   "hash": "e970e3a089ccae2cd07fccc4512d6742f9f9435469c2a9fbd55abc6113d61ae6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}