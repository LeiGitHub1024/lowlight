{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e38bc2a34033>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom_noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.util import random_noise\n",
    "import torch\n",
    "import torch.utils.data as Data \n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 256, 256, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def mbllen_loader(device):\n",
    "    # image => npy\n",
    "    # mbllenPath = './data/mbllen'\n",
    "    # mbllenLowPath = './data/mbllen_lowlight'\n",
    "    # train = []\n",
    "    # train_lowlight = []\n",
    "    # i=5000\n",
    "    # for file in tqdm(os.listdir(mbllenPath)):\n",
    "    #     if(i==0):\n",
    "    #         break\n",
    "    #     i =i-1\n",
    "    #     train_path = os.path.join(mbllenPath, file)\n",
    "    #     if os.path.isfile(train_path) == True:\n",
    "    #         im = np.array(Image.open(train_path))\n",
    "    #         train.append(im)\n",
    "    #     lowlight_path = os.path.join(mbllenLowPath, file)\n",
    "    #     if os.path.isfile(lowlight_path) == True:\n",
    "    #         im = np.array(Image.open(lowlight_path))\n",
    "    #         train_lowlight.append(im)\n",
    "    # np.save(\"./data/mb_train.npy\", train) \n",
    "    # np.save(\"./data/mb_train_lowlight.npy\", train_lowlight) \n",
    "\n",
    "    #load npy\n",
    "    image_train = np.load('./data/mb_train.npy')\n",
    "    image_train = np.reshape(image_train, [-1, 3, 256, 256])\n",
    "    image_train = np.transpose(image_train, [0, 3, 2, 1])\n",
    "\n",
    "    image_lowlight = np.load('./data/mb_train_lowlight.npy') \n",
    "    image_lowlight = np.reshape(image_lowlight, [-1, 3, 256, 256])   \n",
    "    image_lowlight = np.transpose(image_lowlight, [0, 3, 2, 1])\n",
    "    return image_train/255, image_lowlight/255\n",
    "\n",
    "train,train_lowlight = mbllen_loader(device)\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape torch.Size([4000, 3, 256, 256])\n",
      "y_train.shape: torch.Size([4000, 3, 256, 256])\n",
      "X_val.shape: torch.Size([1000, 3, 256, 256])\n",
      "y_val.shape: torch.Size([1000, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# 数据集准备为PyTorch可用的形式，转化为[样本, 通道, 高, 宽]\n",
    "data_X = np.transpose(train, (0, 3, 2, 1))\n",
    "data_Y = np.transpose(train_lowlight, (0, 3, 2, 1))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(data_X, data_Y, test_size=0.2, random_state=123)\n",
    "# 转化为torch张量\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
    "# 将X与y整合在一起\n",
    "train_data = Data.TensorDataset(X_train, y_train)\n",
    "val_data = Data.TensorDataset(X_val, y_val)\n",
    "\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"X_val.shape:\", X_val.shape)\n",
    "print(\"y_val.shape:\", y_val.shape)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a08e6890f1e37f6640bcf115006b91805bef7115f2496f3efee946545d5d6ffd"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('mxy': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
