Namespace(arch='Uformer', att_se=False, batch_size=32, checkpoint=50, dataset='SIDD', embed_dim=32, env='32_1009_3_0', eval_workers=8, global_skip=False, gpu='0', local_skip=False, lr_initial=0.0001, mode='denoising', nepoch=150, norm_layer='nn.LayerNorm', optimizer='adamw', pretrain_weights='./log/Uformer32/models/model_best.pth', resume=False, save_dir='/home/ma-user/work/deNoTr/log', save_images=False, token_mlp='leff', token_projection='linear', train_dir='/home/mist/lowlight/datasets/lol_stage0/train', train_ps=64, train_workers=16, val_dir='/home/mist/lowlight/datasets/lol_stage0/valid', vit_depth=12, vit_dim=256, vit_mlp_dim=512, vit_nheads=8, vit_patch_size=16, vit_share=False, warmup=True, warmup_epochs=3, weight_decay=0.02, win_size=8)
Uformer(
  embed_dim=32, token_projection=linear, token_mlp=leff,win_size=8
  (pos_drop): Dropout(p=0.0, inplace=False)
  (input_proj): InputProj(
    (proj): Sequential(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
  (output_proj): OutputProj(
    (proj): Sequential(
      (0): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (encoderlayer_0): ConvBlock(
    (block): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01, inplace=True)
      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (conv11): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (skipconnection_0): BasicUformerLayer(
    dim=32, input_resolution=(64, 64), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=32, input_resolution=(64, 64), num_heads=1, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=32, win_size=(8, 8), num_heads=1
          (qkv): LinearProjection(
            (to_q): Linear(in_features=32, out_features=32, bias=True)
            (to_kv): Linear(in_features=32, out_features=64, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=32, out_features=32, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=32, out_features=128, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=128, out_features=32, bias=True)
          )
        )
      )
      (1): LeWinTransformerBlock(
        dim=32, input_resolution=(64, 64), num_heads=1, win_size=8, shift_size=4, mlp_ratio=4.0
        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=32, win_size=(8, 8), num_heads=1
          (qkv): LinearProjection(
            (to_q): Linear(in_features=32, out_features=32, bias=True)
            (to_kv): Linear(in_features=32, out_features=64, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=32, out_features=32, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=32, out_features=128, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=128, out_features=32, bias=True)
          )
        )
      )
    )
  )
  (dowsample_0): Downsample(
    (conv): Sequential(
      (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (encoderlayer_1): ConvBlock(
    (block): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01, inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (conv11): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (skipconnection_1): BasicUformerLayer(
    dim=64, input_resolution=(32, 32), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=64, input_resolution=(32, 32), num_heads=2, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=64, win_size=(8, 8), num_heads=2
          (qkv): LinearProjection(
            (to_q): Linear(in_features=64, out_features=64, bias=True)
            (to_kv): Linear(in_features=64, out_features=128, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=64, out_features=256, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=256, out_features=64, bias=True)
          )
        )
      )
      (1): LeWinTransformerBlock(
        dim=64, input_resolution=(32, 32), num_heads=2, win_size=8, shift_size=4, mlp_ratio=4.0
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=64, win_size=(8, 8), num_heads=2
          (qkv): LinearProjection(
            (to_q): Linear(in_features=64, out_features=64, bias=True)
            (to_kv): Linear(in_features=64, out_features=128, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=64, out_features=256, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=256, out_features=64, bias=True)
          )
        )
      )
    )
  )
  (dowsample_1): Downsample(
    (conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (encoderlayer_2): ConvBlock(
    (block): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01, inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (conv11): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
  )
  (skipconnection_2): BasicUformerLayer(
    dim=128, input_resolution=(16, 16), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=128, input_resolution=(16, 16), num_heads=4, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=128, win_size=(8, 8), num_heads=4
          (qkv): LinearProjection(
            (to_q): Linear(in_features=128, out_features=128, bias=True)
            (to_kv): Linear(in_features=128, out_features=256, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=128, out_features=512, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=512, out_features=128, bias=True)
          )
        )
      )
      (1): LeWinTransformerBlock(
        dim=128, input_resolution=(16, 16), num_heads=4, win_size=8, shift_size=4, mlp_ratio=4.0
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=128, win_size=(8, 8), num_heads=4
          (qkv): LinearProjection(
            (to_q): Linear(in_features=128, out_features=128, bias=True)
            (to_kv): Linear(in_features=128, out_features=256, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=128, out_features=512, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=512, out_features=128, bias=True)
          )
        )
      )
    )
  )
  (dowsample_2): Downsample(
    (conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (encoderlayer_3): ConvBlock(
    (block): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01, inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (conv11): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  )
  (skipconnection_3): BasicUformerLayer(
    dim=256, input_resolution=(8, 8), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=256, input_resolution=(8, 8), num_heads=8, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
        )
      )
      (1): LeWinTransformerBlock(
        dim=256, input_resolution=(8, 8), num_heads=8, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
        )
      )
    )
  )
  (dowsample_3): Downsample(
    (conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (resize_0): Upsample(
    (deconv): Sequential(
      (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (buf_0): ConvBlock_1(
    (block): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01, inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (conv11): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  )
  (resize_1): Upsample(
    (deconv): Sequential(
      (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (buf_1): ConvBlock_1(
    (block): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01, inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (conv11): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
  )
  (resize_2): Upsample(
    (deconv): Sequential(
      (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (buf_2): ConvBlock_1(
    (block): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01, inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (conv11): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (resize_3): Upsample(
    (deconv): Sequential(
      (0): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (buf_3): ConvBlock_1(
    (block): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01, inplace=True)
      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (conv11): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (resize_4): OutputProj(
    (proj): Sequential(
      (0): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (recover_0): InputProj(
    (proj): Sequential(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
  (conv): BasicUformerLayer(
    dim=32, input_resolution=(64, 64), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=32, input_resolution=(64, 64), num_heads=16, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=32, win_size=(8, 8), num_heads=16
          (qkv): LinearProjection(
            (to_q): Linear(in_features=32, out_features=32, bias=True)
            (to_kv): Linear(in_features=32, out_features=64, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=32, out_features=32, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=32, out_features=128, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=128, out_features=32, bias=True)
          )
        )
      )
      (1): LeWinTransformerBlock(
        dim=32, input_resolution=(64, 64), num_heads=16, win_size=8, shift_size=4, mlp_ratio=4.0
        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=32, win_size=(8, 8), num_heads=16
          (qkv): LinearProjection(
            (to_q): Linear(in_features=32, out_features=32, bias=True)
            (to_kv): Linear(in_features=32, out_features=64, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=32, out_features=32, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=32, out_features=128, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=128, out_features=32, bias=True)
          )
        )
      )
    )
  )
  (recover_1): Downsample(
    (conv): Sequential(
      (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (recover_2): Downsample(
    (conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (recover_3): Downsample(
    (conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (recover_4): Downsample(
    (conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (upsample_0): Upsample(
    (deconv): Sequential(
      (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (decoderlayer_0): BasicUformerLayer(
    dim=512, input_resolution=(8, 8), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=512, input_resolution=(8, 8), num_heads=16, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=512, win_size=(8, 8), num_heads=16
          (qkv): LinearProjection(
            (to_q): Linear(in_features=512, out_features=512, bias=True)
            (to_kv): Linear(in_features=512, out_features=1024, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=512, out_features=2048, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
      )
      (1): LeWinTransformerBlock(
        dim=512, input_resolution=(8, 8), num_heads=16, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=512, win_size=(8, 8), num_heads=16
          (qkv): LinearProjection(
            (to_q): Linear(in_features=512, out_features=512, bias=True)
            (to_kv): Linear(in_features=512, out_features=1024, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=512, out_features=2048, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
      )
    )
  )
  (upsample_1): Upsample(
    (deconv): Sequential(
      (0): ConvTranspose2d(512, 128, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (decoderlayer_1): BasicUformerLayer(
    dim=256, input_resolution=(16, 16), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=256, input_resolution=(16, 16), num_heads=8, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
        )
      )
      (1): LeWinTransformerBlock(
        dim=256, input_resolution=(16, 16), num_heads=8, win_size=8, shift_size=4, mlp_ratio=4.0
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
        )
      )
    )
  )
  (upsample_2): Upsample(
    (deconv): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (decoderlayer_2): BasicUformerLayer(
    dim=128, input_resolution=(32, 32), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=128, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=128, win_size=(8, 8), num_heads=4
          (qkv): LinearProjection(
            (to_q): Linear(in_features=128, out_features=128, bias=True)
            (to_kv): Linear(in_features=128, out_features=256, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=128, out_features=512, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=512, out_features=128, bias=True)
          )
        )
      )
      (1): LeWinTransformerBlock(
        dim=128, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=4, mlp_ratio=4.0
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=128, win_size=(8, 8), num_heads=4
          (qkv): LinearProjection(
            (to_q): Linear(in_features=128, out_features=128, bias=True)
            (to_kv): Linear(in_features=128, out_features=256, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=128, out_features=512, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=512, out_features=128, bias=True)
          )
        )
      )
    )
  )
  (upsample_3): Upsample(
    (deconv): Sequential(
      (0): ConvTranspose2d(128, 32, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (decoderlayer_3): BasicUformerLayer(
    dim=64, input_resolution=(64, 64), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=64, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=64, win_size=(8, 8), num_heads=2
          (qkv): LinearProjection(
            (to_q): Linear(in_features=64, out_features=64, bias=True)
            (to_kv): Linear(in_features=64, out_features=128, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=64, out_features=256, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=256, out_features=64, bias=True)
          )
        )
      )
      (1): LeWinTransformerBlock(
        dim=64, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=4, mlp_ratio=4.0
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=64, win_size=(8, 8), num_heads=2
          (qkv): LinearProjection(
            (to_q): Linear(in_features=64, out_features=64, bias=True)
            (to_kv): Linear(in_features=64, out_features=128, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=64, out_features=256, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=256, out_features=64, bias=True)
          )
        )
      )
    )
  )
)
[Ep 1 it 29	 PSNR SIDD: 4.5928	] ----  [best_Ep_SIDD 1 best_it_SIDD 29 Best_PSNR_SIDD 4.5928] 
[Ep 1 it 59	 PSNR SIDD: 6.4557	] ----  [best_Ep_SIDD 1 best_it_SIDD 59 Best_PSNR_SIDD 6.4557] 
[Ep 1 it 89	 PSNR SIDD: 6.3048	] ----  [best_Ep_SIDD 1 best_it_SIDD 59 Best_PSNR_SIDD 6.4557] 
[Ep 1 it 119	 PSNR SIDD: 6.5436	] ----  [best_Ep_SIDD 1 best_it_SIDD 119 Best_PSNR_SIDD 6.5436] 
Epoch: 1	Time: 17.9893	Loss: 357.9614	LearningRate 0.000067
[Ep 2 it 29	 PSNR SIDD: 6.8194	] ----  [best_Ep_SIDD 2 best_it_SIDD 29 Best_PSNR_SIDD 6.8194] 
[Ep 2 it 59	 PSNR SIDD: 8.0743	] ----  [best_Ep_SIDD 2 best_it_SIDD 59 Best_PSNR_SIDD 8.0743] 
[Ep 2 it 89	 PSNR SIDD: 9.3125	] ----  [best_Ep_SIDD 2 best_it_SIDD 89 Best_PSNR_SIDD 9.3125] 
[Ep 2 it 119	 PSNR SIDD: 11.4910	] ----  [best_Ep_SIDD 2 best_it_SIDD 119 Best_PSNR_SIDD 11.4910] 
Epoch: 2	Time: 15.3662	Loss: 134.7299	LearningRate 0.000100
[Ep 3 it 29	 PSNR SIDD: 14.0071	] ----  [best_Ep_SIDD 3 best_it_SIDD 29 Best_PSNR_SIDD 14.0071] 
[Ep 3 it 59	 PSNR SIDD: 14.5498	] ----  [best_Ep_SIDD 3 best_it_SIDD 59 Best_PSNR_SIDD 14.5498] 
[Ep 3 it 89	 PSNR SIDD: 14.6956	] ----  [best_Ep_SIDD 3 best_it_SIDD 89 Best_PSNR_SIDD 14.6956] 
[Ep 3 it 119	 PSNR SIDD: 14.5855	] ----  [best_Ep_SIDD 3 best_it_SIDD 89 Best_PSNR_SIDD 14.6956] 
Epoch: 3	Time: 15.5839	Loss: 76.1831	LearningRate 0.000100
[Ep 4 it 29	 PSNR SIDD: 14.8006	] ----  [best_Ep_SIDD 4 best_it_SIDD 29 Best_PSNR_SIDD 14.8006] 
[Ep 4 it 59	 PSNR SIDD: 14.9763	] ----  [best_Ep_SIDD 4 best_it_SIDD 59 Best_PSNR_SIDD 14.9763] 
[Ep 4 it 89	 PSNR SIDD: 14.9679	] ----  [best_Ep_SIDD 4 best_it_SIDD 59 Best_PSNR_SIDD 14.9763] 
[Ep 4 it 119	 PSNR SIDD: 15.0809	] ----  [best_Ep_SIDD 4 best_it_SIDD 119 Best_PSNR_SIDD 15.0809] 
Epoch: 4	Time: 15.2113	Loss: 68.5164	LearningRate 0.000100
[Ep 5 it 29	 PSNR SIDD: 15.2251	] ----  [best_Ep_SIDD 5 best_it_SIDD 29 Best_PSNR_SIDD 15.2251] 
[Ep 5 it 59	 PSNR SIDD: 14.4090	] ----  [best_Ep_SIDD 5 best_it_SIDD 29 Best_PSNR_SIDD 15.2251] 
[Ep 5 it 89	 PSNR SIDD: 14.9639	] ----  [best_Ep_SIDD 5 best_it_SIDD 29 Best_PSNR_SIDD 15.2251] 
[Ep 5 it 119	 PSNR SIDD: 15.1602	] ----  [best_Ep_SIDD 5 best_it_SIDD 29 Best_PSNR_SIDD 15.2251] 
Epoch: 5	Time: 13.8710	Loss: 65.9722	LearningRate 0.000100
[Ep 6 it 29	 PSNR SIDD: 14.4823	] ----  [best_Ep_SIDD 5 best_it_SIDD 29 Best_PSNR_SIDD 15.2251] 
[Ep 6 it 59	 PSNR SIDD: 14.7075	] ----  [best_Ep_SIDD 5 best_it_SIDD 29 Best_PSNR_SIDD 15.2251] 
[Ep 6 it 89	 PSNR SIDD: 14.6862	] ----  [best_Ep_SIDD 5 best_it_SIDD 29 Best_PSNR_SIDD 15.2251] 
[Ep 6 it 119	 PSNR SIDD: 14.7640	] ----  [best_Ep_SIDD 5 best_it_SIDD 29 Best_PSNR_SIDD 15.2251] 
Epoch: 6	Time: 14.4537	Loss: 46.4046	LearningRate 0.000100
[Ep 7 it 29	 PSNR SIDD: 15.0895	] ----  [best_Ep_SIDD 5 best_it_SIDD 29 Best_PSNR_SIDD 15.2251] 
[Ep 7 it 59	 PSNR SIDD: 15.0598	] ----  [best_Ep_SIDD 5 best_it_SIDD 29 Best_PSNR_SIDD 15.2251] 
[Ep 7 it 89	 PSNR SIDD: 15.2036	] ----  [best_Ep_SIDD 5 best_it_SIDD 29 Best_PSNR_SIDD 15.2251] 
[Ep 7 it 119	 PSNR SIDD: 14.6576	] ----  [best_Ep_SIDD 5 best_it_SIDD 29 Best_PSNR_SIDD 15.2251] 
Epoch: 7	Time: 13.5939	Loss: 46.7599	LearningRate 0.000100
[Ep 8 it 29	 PSNR SIDD: 14.6601	] ----  [best_Ep_SIDD 5 best_it_SIDD 29 Best_PSNR_SIDD 15.2251] 
[Ep 8 it 59	 PSNR SIDD: 15.2046	] ----  [best_Ep_SIDD 5 best_it_SIDD 29 Best_PSNR_SIDD 15.2251] 
[Ep 8 it 89	 PSNR SIDD: 14.2829	] ----  [best_Ep_SIDD 5 best_it_SIDD 29 Best_PSNR_SIDD 15.2251] 
[Ep 8 it 119	 PSNR SIDD: 14.9386	] ----  [best_Ep_SIDD 5 best_it_SIDD 29 Best_PSNR_SIDD 15.2251] 
Epoch: 8	Time: 13.4867	Loss: 48.6372	LearningRate 0.000100
[Ep 9 it 29	 PSNR SIDD: 15.4712	] ----  [best_Ep_SIDD 9 best_it_SIDD 29 Best_PSNR_SIDD 15.4712] 
[Ep 9 it 59	 PSNR SIDD: 14.7497	] ----  [best_Ep_SIDD 9 best_it_SIDD 29 Best_PSNR_SIDD 15.4712] 
[Ep 9 it 89	 PSNR SIDD: 13.6788	] ----  [best_Ep_SIDD 9 best_it_SIDD 29 Best_PSNR_SIDD 15.4712] 
[Ep 9 it 119	 PSNR SIDD: 15.3407	] ----  [best_Ep_SIDD 9 best_it_SIDD 29 Best_PSNR_SIDD 15.4712] 
Epoch: 9	Time: 15.7043	Loss: 45.7712	LearningRate 0.000099
[Ep 10 it 29	 PSNR SIDD: 14.0546	] ----  [best_Ep_SIDD 9 best_it_SIDD 29 Best_PSNR_SIDD 15.4712] 
[Ep 10 it 59	 PSNR SIDD: 14.7771	] ----  [best_Ep_SIDD 9 best_it_SIDD 29 Best_PSNR_SIDD 15.4712] 
[Ep 10 it 89	 PSNR SIDD: 15.6451	] ----  [best_Ep_SIDD 10 best_it_SIDD 89 Best_PSNR_SIDD 15.6451] 
[Ep 10 it 119	 PSNR SIDD: 15.8174	] ----  [best_Ep_SIDD 10 best_it_SIDD 119 Best_PSNR_SIDD 15.8174] 
Epoch: 10	Time: 14.2406	Loss: 44.0206	LearningRate 0.000099
[Ep 11 it 29	 PSNR SIDD: 15.4236	] ----  [best_Ep_SIDD 10 best_it_SIDD 119 Best_PSNR_SIDD 15.8174] 
[Ep 11 it 59	 PSNR SIDD: 15.8152	] ----  [best_Ep_SIDD 10 best_it_SIDD 119 Best_PSNR_SIDD 15.8174] 
[Ep 11 it 89	 PSNR SIDD: 14.2602	] ----  [best_Ep_SIDD 10 best_it_SIDD 119 Best_PSNR_SIDD 15.8174] 
[Ep 11 it 119	 PSNR SIDD: 15.6276	] ----  [best_Ep_SIDD 10 best_it_SIDD 119 Best_PSNR_SIDD 15.8174] 
Epoch: 11	Time: 13.4835	Loss: 41.9075	LearningRate 0.000099
[Ep 12 it 29	 PSNR SIDD: 15.0943	] ----  [best_Ep_SIDD 10 best_it_SIDD 119 Best_PSNR_SIDD 15.8174] 
[Ep 12 it 59	 PSNR SIDD: 14.9133	] ----  [best_Ep_SIDD 10 best_it_SIDD 119 Best_PSNR_SIDD 15.8174] 
[Ep 12 it 89	 PSNR SIDD: 15.9370	] ----  [best_Ep_SIDD 12 best_it_SIDD 89 Best_PSNR_SIDD 15.9370] 
[Ep 12 it 119	 PSNR SIDD: 14.7810	] ----  [best_Ep_SIDD 12 best_it_SIDD 89 Best_PSNR_SIDD 15.9370] 
Epoch: 12	Time: 14.0049	Loss: 42.7269	LearningRate 0.000099
[Ep 13 it 29	 PSNR SIDD: 16.1064	] ----  [best_Ep_SIDD 13 best_it_SIDD 29 Best_PSNR_SIDD 16.1064] 
[Ep 13 it 59	 PSNR SIDD: 16.0233	] ----  [best_Ep_SIDD 13 best_it_SIDD 29 Best_PSNR_SIDD 16.1064] 
[Ep 13 it 89	 PSNR SIDD: 15.4552	] ----  [best_Ep_SIDD 13 best_it_SIDD 29 Best_PSNR_SIDD 16.1064] 
[Ep 13 it 119	 PSNR SIDD: 16.2132	] ----  [best_Ep_SIDD 13 best_it_SIDD 119 Best_PSNR_SIDD 16.2132] 
Epoch: 13	Time: 15.6946	Loss: 39.2802	LearningRate 0.000099
[Ep 14 it 29	 PSNR SIDD: 15.4176	] ----  [best_Ep_SIDD 13 best_it_SIDD 119 Best_PSNR_SIDD 16.2132] 
[Ep 14 it 59	 PSNR SIDD: 16.1637	] ----  [best_Ep_SIDD 13 best_it_SIDD 119 Best_PSNR_SIDD 16.2132] 
[Ep 14 it 89	 PSNR SIDD: 16.1833	] ----  [best_Ep_SIDD 13 best_it_SIDD 119 Best_PSNR_SIDD 16.2132] 
[Ep 14 it 119	 PSNR SIDD: 16.2311	] ----  [best_Ep_SIDD 14 best_it_SIDD 119 Best_PSNR_SIDD 16.2311] 
Epoch: 14	Time: 14.2926	Loss: 38.4927	LearningRate 0.000098
[Ep 15 it 29	 PSNR SIDD: 15.5030	] ----  [best_Ep_SIDD 14 best_it_SIDD 119 Best_PSNR_SIDD 16.2311] 
[Ep 15 it 59	 PSNR SIDD: 15.4155	] ----  [best_Ep_SIDD 14 best_it_SIDD 119 Best_PSNR_SIDD 16.2311] 
[Ep 15 it 89	 PSNR SIDD: 16.0624	] ----  [best_Ep_SIDD 14 best_it_SIDD 119 Best_PSNR_SIDD 16.2311] 
[Ep 15 it 119	 PSNR SIDD: 16.1698	] ----  [best_Ep_SIDD 14 best_it_SIDD 119 Best_PSNR_SIDD 16.2311] 
Epoch: 15	Time: 14.2511	Loss: 39.2434	LearningRate 0.000098
[Ep 16 it 29	 PSNR SIDD: 15.4904	] ----  [best_Ep_SIDD 14 best_it_SIDD 119 Best_PSNR_SIDD 16.2311] 
[Ep 16 it 59	 PSNR SIDD: 15.9534	] ----  [best_Ep_SIDD 14 best_it_SIDD 119 Best_PSNR_SIDD 16.2311] 
[Ep 16 it 89	 PSNR SIDD: 16.1640	] ----  [best_Ep_SIDD 14 best_it_SIDD 119 Best_PSNR_SIDD 16.2311] 
[Ep 16 it 119	 PSNR SIDD: 15.7873	] ----  [best_Ep_SIDD 14 best_it_SIDD 119 Best_PSNR_SIDD 16.2311] 
Epoch: 16	Time: 13.7363	Loss: 37.9488	LearningRate 0.000098
[Ep 17 it 29	 PSNR SIDD: 16.2541	] ----  [best_Ep_SIDD 17 best_it_SIDD 29 Best_PSNR_SIDD 16.2541] 
[Ep 17 it 59	 PSNR SIDD: 16.2661	] ----  [best_Ep_SIDD 17 best_it_SIDD 59 Best_PSNR_SIDD 16.2661] 
[Ep 17 it 89	 PSNR SIDD: 16.3511	] ----  [best_Ep_SIDD 17 best_it_SIDD 89 Best_PSNR_SIDD 16.3511] 
[Ep 17 it 119	 PSNR SIDD: 16.3226	] ----  [best_Ep_SIDD 17 best_it_SIDD 89 Best_PSNR_SIDD 16.3511] 
Epoch: 17	Time: 18.0328	Loss: 37.3478	LearningRate 0.000098
[Ep 18 it 29	 PSNR SIDD: 16.2022	] ----  [best_Ep_SIDD 17 best_it_SIDD 89 Best_PSNR_SIDD 16.3511] 
[Ep 18 it 59	 PSNR SIDD: 16.2696	] ----  [best_Ep_SIDD 17 best_it_SIDD 89 Best_PSNR_SIDD 16.3511] 
[Ep 18 it 89	 PSNR SIDD: 16.3115	] ----  [best_Ep_SIDD 17 best_it_SIDD 89 Best_PSNR_SIDD 16.3511] 
[Ep 18 it 119	 PSNR SIDD: 16.4029	] ----  [best_Ep_SIDD 18 best_it_SIDD 119 Best_PSNR_SIDD 16.4029] 
Epoch: 18	Time: 14.1774	Loss: 37.1304	LearningRate 0.000097
[Ep 19 it 29	 PSNR SIDD: 16.1198	] ----  [best_Ep_SIDD 18 best_it_SIDD 119 Best_PSNR_SIDD 16.4029] 
[Ep 19 it 59	 PSNR SIDD: 15.6770	] ----  [best_Ep_SIDD 18 best_it_SIDD 119 Best_PSNR_SIDD 16.4029] 
[Ep 19 it 89	 PSNR SIDD: 15.1153	] ----  [best_Ep_SIDD 18 best_it_SIDD 119 Best_PSNR_SIDD 16.4029] 
[Ep 19 it 119	 PSNR SIDD: 16.4454	] ----  [best_Ep_SIDD 19 best_it_SIDD 119 Best_PSNR_SIDD 16.4454] 
Epoch: 19	Time: 14.8671	Loss: 37.4927	LearningRate 0.000097
[Ep 20 it 29	 PSNR SIDD: 16.5882	] ----  [best_Ep_SIDD 20 best_it_SIDD 29 Best_PSNR_SIDD 16.5882] 
[Ep 20 it 59	 PSNR SIDD: 15.7333	] ----  [best_Ep_SIDD 20 best_it_SIDD 29 Best_PSNR_SIDD 16.5882] 
[Ep 20 it 89	 PSNR SIDD: 15.5588	] ----  [best_Ep_SIDD 20 best_it_SIDD 29 Best_PSNR_SIDD 16.5882] 
[Ep 20 it 119	 PSNR SIDD: 15.8097	] ----  [best_Ep_SIDD 20 best_it_SIDD 29 Best_PSNR_SIDD 16.5882] 
Epoch: 20	Time: 13.8484	Loss: 36.5570	LearningRate 0.000096
[Ep 21 it 29	 PSNR SIDD: 16.3659	] ----  [best_Ep_SIDD 20 best_it_SIDD 29 Best_PSNR_SIDD 16.5882] 
[Ep 21 it 59	 PSNR SIDD: 16.1785	] ----  [best_Ep_SIDD 20 best_it_SIDD 29 Best_PSNR_SIDD 16.5882] 
[Ep 21 it 89	 PSNR SIDD: 15.3192	] ----  [best_Ep_SIDD 20 best_it_SIDD 29 Best_PSNR_SIDD 16.5882] 
[Ep 21 it 119	 PSNR SIDD: 16.7577	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
Epoch: 21	Time: 14.9464	Loss: 35.4174	LearningRate 0.000096
[Ep 22 it 29	 PSNR SIDD: 16.1914	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 22 it 59	 PSNR SIDD: 15.7670	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 22 it 89	 PSNR SIDD: 15.5496	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 22 it 119	 PSNR SIDD: 15.9070	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
Epoch: 22	Time: 13.9887	Loss: 35.9456	LearningRate 0.000096
[Ep 23 it 29	 PSNR SIDD: 15.5351	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 23 it 59	 PSNR SIDD: 16.5738	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 23 it 89	 PSNR SIDD: 16.6269	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 23 it 119	 PSNR SIDD: 15.9543	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
Epoch: 23	Time: 14.1243	Loss: 35.1495	LearningRate 0.000095
[Ep 24 it 29	 PSNR SIDD: 15.8223	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 24 it 59	 PSNR SIDD: 16.0459	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 24 it 89	 PSNR SIDD: 16.0245	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 24 it 119	 PSNR SIDD: 16.2600	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
Epoch: 24	Time: 13.4458	Loss: 34.7980	LearningRate 0.000095
[Ep 25 it 29	 PSNR SIDD: 16.7127	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 25 it 59	 PSNR SIDD: 16.5323	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 25 it 89	 PSNR SIDD: 16.5998	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 25 it 119	 PSNR SIDD: 16.2650	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
Epoch: 25	Time: 13.9557	Loss: 34.9598	LearningRate 0.000094
[Ep 26 it 29	 PSNR SIDD: 15.7670	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 26 it 59	 PSNR SIDD: 16.2338	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 26 it 89	 PSNR SIDD: 16.5443	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 26 it 119	 PSNR SIDD: 16.5664	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
Epoch: 26	Time: 14.9138	Loss: 34.5293	LearningRate 0.000094
[Ep 27 it 29	 PSNR SIDD: 16.5429	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 27 it 59	 PSNR SIDD: 16.4750	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 27 it 89	 PSNR SIDD: 16.5593	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 27 it 119	 PSNR SIDD: 16.7013	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
Epoch: 27	Time: 14.3588	Loss: 34.5431	LearningRate 0.000093
[Ep 28 it 29	 PSNR SIDD: 16.1201	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 28 it 59	 PSNR SIDD: 16.4474	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 28 it 89	 PSNR SIDD: 16.5655	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 28 it 119	 PSNR SIDD: 16.6483	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
Epoch: 28	Time: 14.0035	Loss: 34.2685	LearningRate 0.000093
[Ep 29 it 29	 PSNR SIDD: 16.4978	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 29 it 59	 PSNR SIDD: 16.5029	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 29 it 89	 PSNR SIDD: 16.0946	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 29 it 119	 PSNR SIDD: 16.3666	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
Epoch: 29	Time: 13.3972	Loss: 33.8402	LearningRate 0.000092
[Ep 30 it 29	 PSNR SIDD: 15.9853	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 30 it 59	 PSNR SIDD: 16.5166	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 30 it 89	 PSNR SIDD: 16.6265	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 30 it 119	 PSNR SIDD: 16.4876	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
Epoch: 30	Time: 13.5856	Loss: 34.1187	LearningRate 0.000091
[Ep 31 it 29	 PSNR SIDD: 16.3880	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 31 it 59	 PSNR SIDD: 16.0272	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 31 it 89	 PSNR SIDD: 16.6096	] ----  [best_Ep_SIDD 21 best_it_SIDD 119 Best_PSNR_SIDD 16.7577] 
[Ep 31 it 119	 PSNR SIDD: 16.8912	] ----  [best_Ep_SIDD 31 best_it_SIDD 119 Best_PSNR_SIDD 16.8912] 
Epoch: 31	Time: 14.2535	Loss: 33.0134	LearningRate 0.000091
[Ep 32 it 29	 PSNR SIDD: 16.5252	] ----  [best_Ep_SIDD 31 best_it_SIDD 119 Best_PSNR_SIDD 16.8912] 
[Ep 32 it 59	 PSNR SIDD: 16.4200	] ----  [best_Ep_SIDD 31 best_it_SIDD 119 Best_PSNR_SIDD 16.8912] 
[Ep 32 it 89	 PSNR SIDD: 16.4907	] ----  [best_Ep_SIDD 31 best_it_SIDD 119 Best_PSNR_SIDD 16.8912] 
[Ep 32 it 119	 PSNR SIDD: 16.5060	] ----  [best_Ep_SIDD 31 best_it_SIDD 119 Best_PSNR_SIDD 16.8912] 
Epoch: 32	Time: 13.8679	Loss: 33.3024	LearningRate 0.000090
[Ep 33 it 29	 PSNR SIDD: 15.9944	] ----  [best_Ep_SIDD 31 best_it_SIDD 119 Best_PSNR_SIDD 16.8912] 
[Ep 33 it 59	 PSNR SIDD: 16.3789	] ----  [best_Ep_SIDD 31 best_it_SIDD 119 Best_PSNR_SIDD 16.8912] 
[Ep 33 it 89	 PSNR SIDD: 17.0591	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
[Ep 33 it 119	 PSNR SIDD: 16.8764	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
Epoch: 33	Time: 14.3475	Loss: 32.4895	LearningRate 0.000090
[Ep 34 it 29	 PSNR SIDD: 16.7251	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
[Ep 34 it 59	 PSNR SIDD: 15.9408	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
[Ep 34 it 89	 PSNR SIDD: 16.7884	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
[Ep 34 it 119	 PSNR SIDD: 16.8205	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
Epoch: 34	Time: 14.2786	Loss: 33.1312	LearningRate 0.000089
[Ep 35 it 29	 PSNR SIDD: 16.8916	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
[Ep 35 it 59	 PSNR SIDD: 16.6895	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
[Ep 35 it 89	 PSNR SIDD: 16.2188	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
[Ep 35 it 119	 PSNR SIDD: 16.7260	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
Epoch: 35	Time: 13.5681	Loss: 32.3529	LearningRate 0.000088
[Ep 36 it 29	 PSNR SIDD: 16.7659	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
[Ep 36 it 59	 PSNR SIDD: 16.6748	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
[Ep 36 it 89	 PSNR SIDD: 16.6475	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
[Ep 36 it 119	 PSNR SIDD: 16.8707	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
Epoch: 36	Time: 13.6748	Loss: 32.2069	LearningRate 0.000088
[Ep 37 it 29	 PSNR SIDD: 16.0765	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
[Ep 37 it 59	 PSNR SIDD: 16.4938	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
[Ep 37 it 89	 PSNR SIDD: 16.6341	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
[Ep 37 it 119	 PSNR SIDD: 16.5199	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
Epoch: 37	Time: 13.7072	Loss: 33.3340	LearningRate 0.000087
[Ep 38 it 29	 PSNR SIDD: 16.5778	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
[Ep 38 it 59	 PSNR SIDD: 16.9077	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
[Ep 38 it 89	 PSNR SIDD: 16.7318	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
[Ep 38 it 119	 PSNR SIDD: 16.5725	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
Epoch: 38	Time: 13.8359	Loss: 31.5266	LearningRate 0.000086
[Ep 39 it 29	 PSNR SIDD: 16.9168	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
[Ep 39 it 59	 PSNR SIDD: 16.8204	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
[Ep 39 it 89	 PSNR SIDD: 16.2538	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
[Ep 39 it 119	 PSNR SIDD: 16.5402	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
Epoch: 39	Time: 14.4221	Loss: 32.2073	LearningRate 0.000085
[Ep 40 it 29	 PSNR SIDD: 16.9668	] ----  [best_Ep_SIDD 33 best_it_SIDD 89 Best_PSNR_SIDD 17.0591] 
[Ep 40 it 59	 PSNR SIDD: 17.1289	] ----  [best_Ep_SIDD 40 best_it_SIDD 59 Best_PSNR_SIDD 17.1289] 
[Ep 40 it 89	 PSNR SIDD: 16.8027	] ----  [best_Ep_SIDD 40 best_it_SIDD 59 Best_PSNR_SIDD 17.1289] 
[Ep 40 it 119	 PSNR SIDD: 16.7970	] ----  [best_Ep_SIDD 40 best_it_SIDD 59 Best_PSNR_SIDD 17.1289] 
Epoch: 40	Time: 15.1264	Loss: 32.0304	LearningRate 0.000085
[Ep 41 it 29	 PSNR SIDD: 16.7186	] ----  [best_Ep_SIDD 40 best_it_SIDD 59 Best_PSNR_SIDD 17.1289] 
[Ep 41 it 59	 PSNR SIDD: 16.7649	] ----  [best_Ep_SIDD 40 best_it_SIDD 59 Best_PSNR_SIDD 17.1289] 
[Ep 41 it 89	 PSNR SIDD: 17.0209	] ----  [best_Ep_SIDD 40 best_it_SIDD 59 Best_PSNR_SIDD 17.1289] 
[Ep 41 it 119	 PSNR SIDD: 16.1622	] ----  [best_Ep_SIDD 40 best_it_SIDD 59 Best_PSNR_SIDD 17.1289] 
Epoch: 41	Time: 13.7933	Loss: 31.9310	LearningRate 0.000084
[Ep 42 it 29	 PSNR SIDD: 16.9944	] ----  [best_Ep_SIDD 40 best_it_SIDD 59 Best_PSNR_SIDD 17.1289] 
[Ep 42 it 59	 PSNR SIDD: 17.0373	] ----  [best_Ep_SIDD 40 best_it_SIDD 59 Best_PSNR_SIDD 17.1289] 
[Ep 42 it 89	 PSNR SIDD: 16.9786	] ----  [best_Ep_SIDD 40 best_it_SIDD 59 Best_PSNR_SIDD 17.1289] 
[Ep 42 it 119	 PSNR SIDD: 16.6571	] ----  [best_Ep_SIDD 40 best_it_SIDD 59 Best_PSNR_SIDD 17.1289] 
Epoch: 42	Time: 14.1682	Loss: 31.7114	LearningRate 0.000083
[Ep 43 it 29	 PSNR SIDD: 16.6071	] ----  [best_Ep_SIDD 40 best_it_SIDD 59 Best_PSNR_SIDD 17.1289] 
[Ep 43 it 59	 PSNR SIDD: 16.6852	] ----  [best_Ep_SIDD 40 best_it_SIDD 59 Best_PSNR_SIDD 17.1289] 
[Ep 43 it 89	 PSNR SIDD: 17.4002	] ----  [best_Ep_SIDD 43 best_it_SIDD 89 Best_PSNR_SIDD 17.4002] 
[Ep 43 it 119	 PSNR SIDD: 17.1334	] ----  [best_Ep_SIDD 43 best_it_SIDD 89 Best_PSNR_SIDD 17.4002] 
Epoch: 43	Time: 14.5745	Loss: 31.1906	LearningRate 0.000082
[Ep 44 it 29	 PSNR SIDD: 17.3536	] ----  [best_Ep_SIDD 43 best_it_SIDD 89 Best_PSNR_SIDD 17.4002] 
[Ep 44 it 59	 PSNR SIDD: 16.6657	] ----  [best_Ep_SIDD 43 best_it_SIDD 89 Best_PSNR_SIDD 17.4002] 
[Ep 44 it 89	 PSNR SIDD: 16.4607	] ----  [best_Ep_SIDD 43 best_it_SIDD 89 Best_PSNR_SIDD 17.4002] 
[Ep 44 it 119	 PSNR SIDD: 17.0809	] ----  [best_Ep_SIDD 43 best_it_SIDD 89 Best_PSNR_SIDD 17.4002] 
Epoch: 44	Time: 13.5238	Loss: 29.8153	LearningRate 0.000081
[Ep 45 it 29	 PSNR SIDD: 17.0068	] ----  [best_Ep_SIDD 43 best_it_SIDD 89 Best_PSNR_SIDD 17.4002] 
[Ep 45 it 59	 PSNR SIDD: 16.9064	] ----  [best_Ep_SIDD 43 best_it_SIDD 89 Best_PSNR_SIDD 17.4002] 
[Ep 45 it 89	 PSNR SIDD: 17.1572	] ----  [best_Ep_SIDD 43 best_it_SIDD 89 Best_PSNR_SIDD 17.4002] 
[Ep 45 it 119	 PSNR SIDD: 17.3719	] ----  [best_Ep_SIDD 43 best_it_SIDD 89 Best_PSNR_SIDD 17.4002] 
Epoch: 45	Time: 13.4705	Loss: 29.5524	LearningRate 0.000081
[Ep 46 it 29	 PSNR SIDD: 17.1928	] ----  [best_Ep_SIDD 43 best_it_SIDD 89 Best_PSNR_SIDD 17.4002] 
[Ep 46 it 59	 PSNR SIDD: 17.3115	] ----  [best_Ep_SIDD 43 best_it_SIDD 89 Best_PSNR_SIDD 17.4002] 
[Ep 46 it 89	 PSNR SIDD: 17.2157	] ----  [best_Ep_SIDD 43 best_it_SIDD 89 Best_PSNR_SIDD 17.4002] 
[Ep 46 it 119	 PSNR SIDD: 16.8005	] ----  [best_Ep_SIDD 43 best_it_SIDD 89 Best_PSNR_SIDD 17.4002] 
Epoch: 46	Time: 13.3180	Loss: 29.2810	LearningRate 0.000080
[Ep 47 it 29	 PSNR SIDD: 17.4825	] ----  [best_Ep_SIDD 47 best_it_SIDD 29 Best_PSNR_SIDD 17.4825] 
[Ep 47 it 59	 PSNR SIDD: 16.8532	] ----  [best_Ep_SIDD 47 best_it_SIDD 29 Best_PSNR_SIDD 17.4825] 
[Ep 47 it 89	 PSNR SIDD: 17.5295	] ----  [best_Ep_SIDD 47 best_it_SIDD 89 Best_PSNR_SIDD 17.5295] 
[Ep 47 it 119	 PSNR SIDD: 17.4335	] ----  [best_Ep_SIDD 47 best_it_SIDD 89 Best_PSNR_SIDD 17.5295] 
Epoch: 47	Time: 13.9874	Loss: 27.8257	LearningRate 0.000079
[Ep 48 it 29	 PSNR SIDD: 17.1484	] ----  [best_Ep_SIDD 47 best_it_SIDD 89 Best_PSNR_SIDD 17.5295] 
[Ep 48 it 59	 PSNR SIDD: 17.3197	] ----  [best_Ep_SIDD 47 best_it_SIDD 89 Best_PSNR_SIDD 17.5295] 
[Ep 48 it 89	 PSNR SIDD: 17.6991	] ----  [best_Ep_SIDD 48 best_it_SIDD 89 Best_PSNR_SIDD 17.6991] 
[Ep 48 it 119	 PSNR SIDD: 16.7008	] ----  [best_Ep_SIDD 48 best_it_SIDD 89 Best_PSNR_SIDD 17.6991] 
Epoch: 48	Time: 14.2570	Loss: 27.7165	LearningRate 0.000078
[Ep 49 it 29	 PSNR SIDD: 17.4216	] ----  [best_Ep_SIDD 48 best_it_SIDD 89 Best_PSNR_SIDD 17.6991] 
[Ep 49 it 59	 PSNR SIDD: 17.7951	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
[Ep 49 it 89	 PSNR SIDD: 16.5622	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
[Ep 49 it 119	 PSNR SIDD: 17.7217	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
Epoch: 49	Time: 13.7594	Loss: 27.5704	LearningRate 0.000077
[Ep 50 it 29	 PSNR SIDD: 17.4710	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
[Ep 50 it 59	 PSNR SIDD: 17.5128	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
[Ep 50 it 89	 PSNR SIDD: 17.6705	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
[Ep 50 it 119	 PSNR SIDD: 17.5332	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
Epoch: 50	Time: 13.9090	Loss: 27.2235	LearningRate 0.000076
[Ep 51 it 29	 PSNR SIDD: 17.2608	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
[Ep 51 it 59	 PSNR SIDD: 17.2451	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
[Ep 51 it 89	 PSNR SIDD: 17.2137	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
[Ep 51 it 119	 PSNR SIDD: 17.6214	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
Epoch: 51	Time: 13.6429	Loss: 27.0333	LearningRate 0.000075
[Ep 52 it 29	 PSNR SIDD: 17.7370	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
[Ep 52 it 59	 PSNR SIDD: 17.3779	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
[Ep 52 it 89	 PSNR SIDD: 17.7809	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
[Ep 52 it 119	 PSNR SIDD: 17.3862	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
Epoch: 52	Time: 13.8966	Loss: 27.1419	LearningRate 0.000074
[Ep 53 it 29	 PSNR SIDD: 17.4012	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
[Ep 53 it 59	 PSNR SIDD: 17.7301	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
[Ep 53 it 89	 PSNR SIDD: 17.7117	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
[Ep 53 it 119	 PSNR SIDD: 17.3610	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
Epoch: 53	Time: 14.1967	Loss: 26.6924	LearningRate 0.000073
[Ep 54 it 29	 PSNR SIDD: 17.4380	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
[Ep 54 it 59	 PSNR SIDD: 17.7695	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
[Ep 54 it 89	 PSNR SIDD: 17.5848	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
[Ep 54 it 119	 PSNR SIDD: 17.6827	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
Epoch: 54	Time: 14.3980	Loss: 26.7866	LearningRate 0.000072
[Ep 55 it 29	 PSNR SIDD: 17.5838	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
[Ep 55 it 59	 PSNR SIDD: 17.1154	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
[Ep 55 it 89	 PSNR SIDD: 17.7092	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
[Ep 55 it 119	 PSNR SIDD: 17.7759	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 17.7951] 
Epoch: 55	Time: 12.9136	Loss: 25.7750	LearningRate 0.000072
[Ep 56 it 29	 PSNR SIDD: 17.8396	] ----  [best_Ep_SIDD 56 best_it_SIDD 29 Best_PSNR_SIDD 17.8396] 
[Ep 56 it 59	 PSNR SIDD: 18.0753	] ----  [best_Ep_SIDD 56 best_it_SIDD 59 Best_PSNR_SIDD 18.0753] 
[Ep 56 it 89	 PSNR SIDD: 17.4445	] ----  [best_Ep_SIDD 56 best_it_SIDD 59 Best_PSNR_SIDD 18.0753] 
[Ep 56 it 119	 PSNR SIDD: 17.8198	] ----  [best_Ep_SIDD 56 best_it_SIDD 59 Best_PSNR_SIDD 18.0753] 
Epoch: 56	Time: 14.7539	Loss: 25.6042	LearningRate 0.000071
[Ep 57 it 29	 PSNR SIDD: 18.0389	] ----  [best_Ep_SIDD 56 best_it_SIDD 59 Best_PSNR_SIDD 18.0753] 
[Ep 57 it 59	 PSNR SIDD: 18.1189	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.1189] 
[Ep 57 it 89	 PSNR SIDD: 17.5174	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.1189] 
[Ep 57 it 119	 PSNR SIDD: 18.0424	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.1189] 
Epoch: 57	Time: 14.4359	Loss: 25.5639	LearningRate 0.000070
[Ep 58 it 29	 PSNR SIDD: 18.0641	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.1189] 
[Ep 58 it 59	 PSNR SIDD: 18.1266	] ----  [best_Ep_SIDD 58 best_it_SIDD 59 Best_PSNR_SIDD 18.1266] 
[Ep 58 it 89	 PSNR SIDD: 17.2079	] ----  [best_Ep_SIDD 58 best_it_SIDD 59 Best_PSNR_SIDD 18.1266] 
[Ep 58 it 119	 PSNR SIDD: 18.1843	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
Epoch: 58	Time: 13.7817	Loss: 27.0500	LearningRate 0.000069
[Ep 59 it 29	 PSNR SIDD: 17.4679	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
[Ep 59 it 59	 PSNR SIDD: 17.7264	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
[Ep 59 it 89	 PSNR SIDD: 18.0830	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
[Ep 59 it 119	 PSNR SIDD: 17.8021	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
Epoch: 59	Time: 13.3139	Loss: 26.6522	LearningRate 0.000068
[Ep 60 it 29	 PSNR SIDD: 17.7132	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
[Ep 60 it 59	 PSNR SIDD: 17.9544	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
[Ep 60 it 89	 PSNR SIDD: 17.8049	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
[Ep 60 it 119	 PSNR SIDD: 17.7720	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
Epoch: 60	Time: 13.3799	Loss: 25.7424	LearningRate 0.000067
[Ep 61 it 29	 PSNR SIDD: 17.9845	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
[Ep 61 it 59	 PSNR SIDD: 17.0263	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
[Ep 61 it 89	 PSNR SIDD: 18.0604	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
[Ep 61 it 119	 PSNR SIDD: 17.9395	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
Epoch: 61	Time: 13.4967	Loss: 25.7159	LearningRate 0.000066
[Ep 62 it 29	 PSNR SIDD: 18.0955	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
[Ep 62 it 59	 PSNR SIDD: 18.1817	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
[Ep 62 it 89	 PSNR SIDD: 17.4203	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
[Ep 62 it 119	 PSNR SIDD: 18.1342	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
Epoch: 62	Time: 13.4456	Loss: 25.6908	LearningRate 0.000065
[Ep 63 it 29	 PSNR SIDD: 17.7672	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
[Ep 63 it 59	 PSNR SIDD: 17.8877	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
[Ep 63 it 89	 PSNR SIDD: 17.9620	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
[Ep 63 it 119	 PSNR SIDD: 18.1526	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
Epoch: 63	Time: 12.9812	Loss: 25.1302	LearningRate 0.000064
[Ep 64 it 29	 PSNR SIDD: 17.7076	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
[Ep 64 it 59	 PSNR SIDD: 17.9839	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
[Ep 64 it 89	 PSNR SIDD: 18.1753	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
[Ep 64 it 119	 PSNR SIDD: 17.9845	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
Epoch: 64	Time: 13.2941	Loss: 24.7697	LearningRate 0.000063
[Ep 65 it 29	 PSNR SIDD: 17.0634	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
[Ep 65 it 59	 PSNR SIDD: 17.9364	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
[Ep 65 it 89	 PSNR SIDD: 17.4764	] ----  [best_Ep_SIDD 58 best_it_SIDD 119 Best_PSNR_SIDD 18.1843] 
[Ep 65 it 119	 PSNR SIDD: 18.3187	] ----  [best_Ep_SIDD 65 best_it_SIDD 119 Best_PSNR_SIDD 18.3187] 
Epoch: 65	Time: 14.2636	Loss: 25.1489	LearningRate 0.000062
[Ep 66 it 29	 PSNR SIDD: 17.4993	] ----  [best_Ep_SIDD 65 best_it_SIDD 119 Best_PSNR_SIDD 18.3187] 
[Ep 66 it 59	 PSNR SIDD: 18.1492	] ----  [best_Ep_SIDD 65 best_it_SIDD 119 Best_PSNR_SIDD 18.3187] 
[Ep 66 it 89	 PSNR SIDD: 18.1856	] ----  [best_Ep_SIDD 65 best_it_SIDD 119 Best_PSNR_SIDD 18.3187] 
[Ep 66 it 119	 PSNR SIDD: 18.1057	] ----  [best_Ep_SIDD 65 best_it_SIDD 119 Best_PSNR_SIDD 18.3187] 
Epoch: 66	Time: 13.2847	Loss: 25.0655	LearningRate 0.000061
[Ep 67 it 29	 PSNR SIDD: 17.8116	] ----  [best_Ep_SIDD 65 best_it_SIDD 119 Best_PSNR_SIDD 18.3187] 
[Ep 67 it 59	 PSNR SIDD: 17.3339	] ----  [best_Ep_SIDD 65 best_it_SIDD 119 Best_PSNR_SIDD 18.3187] 
[Ep 67 it 89	 PSNR SIDD: 18.2663	] ----  [best_Ep_SIDD 65 best_it_SIDD 119 Best_PSNR_SIDD 18.3187] 
[Ep 67 it 119	 PSNR SIDD: 18.4943	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
Epoch: 67	Time: 14.6406	Loss: 25.5317	LearningRate 0.000059
[Ep 68 it 29	 PSNR SIDD: 18.3175	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
[Ep 68 it 59	 PSNR SIDD: 18.1201	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
[Ep 68 it 89	 PSNR SIDD: 17.6351	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
[Ep 68 it 119	 PSNR SIDD: 17.7354	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
Epoch: 68	Time: 14.1093	Loss: 24.4744	LearningRate 0.000058
[Ep 69 it 29	 PSNR SIDD: 18.2994	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
[Ep 69 it 59	 PSNR SIDD: 18.3280	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
[Ep 69 it 89	 PSNR SIDD: 18.1756	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
[Ep 69 it 119	 PSNR SIDD: 17.7956	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
Epoch: 69	Time: 13.5392	Loss: 24.5029	LearningRate 0.000057
[Ep 70 it 29	 PSNR SIDD: 17.8142	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
[Ep 70 it 59	 PSNR SIDD: 17.6392	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
[Ep 70 it 89	 PSNR SIDD: 17.8958	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
[Ep 70 it 119	 PSNR SIDD: 18.3021	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
Epoch: 70	Time: 13.8458	Loss: 25.0478	LearningRate 0.000056
[Ep 71 it 29	 PSNR SIDD: 17.8265	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
[Ep 71 it 59	 PSNR SIDD: 17.4597	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
[Ep 71 it 89	 PSNR SIDD: 17.8287	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
[Ep 71 it 119	 PSNR SIDD: 17.8967	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
Epoch: 71	Time: 13.4949	Loss: 24.8070	LearningRate 0.000055
[Ep 72 it 29	 PSNR SIDD: 18.0157	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
[Ep 72 it 59	 PSNR SIDD: 17.9814	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
[Ep 72 it 89	 PSNR SIDD: 17.5106	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
[Ep 72 it 119	 PSNR SIDD: 18.1141	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
Epoch: 72	Time: 13.1832	Loss: 24.7587	LearningRate 0.000054
[Ep 73 it 29	 PSNR SIDD: 17.3689	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
[Ep 73 it 59	 PSNR SIDD: 17.8864	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
[Ep 73 it 89	 PSNR SIDD: 18.2523	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
[Ep 73 it 119	 PSNR SIDD: 17.6679	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
Epoch: 73	Time: 12.8172	Loss: 24.0549	LearningRate 0.000053
[Ep 74 it 29	 PSNR SIDD: 17.8282	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
[Ep 74 it 59	 PSNR SIDD: 17.7764	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
[Ep 74 it 89	 PSNR SIDD: 17.8002	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
[Ep 74 it 119	 PSNR SIDD: 18.1043	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
Epoch: 74	Time: 13.4547	Loss: 24.5006	LearningRate 0.000052
[Ep 75 it 29	 PSNR SIDD: 17.6720	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
[Ep 75 it 59	 PSNR SIDD: 17.5482	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
[Ep 75 it 89	 PSNR SIDD: 18.0766	] ----  [best_Ep_SIDD 67 best_it_SIDD 119 Best_PSNR_SIDD 18.4943] 
[Ep 75 it 119	 PSNR SIDD: 18.7493	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 75	Time: 14.2427	Loss: 24.7330	LearningRate 0.000051
[Ep 76 it 29	 PSNR SIDD: 18.4113	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 76 it 59	 PSNR SIDD: 17.7288	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 76 it 89	 PSNR SIDD: 18.3065	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 76 it 119	 PSNR SIDD: 17.5309	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 76	Time: 13.7839	Loss: 24.0329	LearningRate 0.000050
[Ep 77 it 29	 PSNR SIDD: 18.2330	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 77 it 59	 PSNR SIDD: 17.5002	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 77 it 89	 PSNR SIDD: 18.1155	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 77 it 119	 PSNR SIDD: 18.4318	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 77	Time: 13.8528	Loss: 24.7705	LearningRate 0.000049
[Ep 78 it 29	 PSNR SIDD: 18.2149	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 78 it 59	 PSNR SIDD: 18.0076	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 78 it 89	 PSNR SIDD: 18.2489	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 78 it 119	 PSNR SIDD: 18.1023	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 78	Time: 12.6125	Loss: 24.0206	LearningRate 0.000048
[Ep 79 it 29	 PSNR SIDD: 18.3330	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 79 it 59	 PSNR SIDD: 18.1796	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 79 it 89	 PSNR SIDD: 18.3956	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 79 it 119	 PSNR SIDD: 18.1824	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 79	Time: 13.9575	Loss: 24.3390	LearningRate 0.000047
[Ep 80 it 29	 PSNR SIDD: 18.4040	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 80 it 59	 PSNR SIDD: 18.3601	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 80 it 89	 PSNR SIDD: 18.0579	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 80 it 119	 PSNR SIDD: 18.5601	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 80	Time: 13.3343	Loss: 24.3963	LearningRate 0.000046
[Ep 81 it 29	 PSNR SIDD: 18.1476	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 81 it 59	 PSNR SIDD: 18.3915	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 81 it 89	 PSNR SIDD: 18.1677	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 81 it 119	 PSNR SIDD: 18.2990	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 81	Time: 13.1093	Loss: 23.5757	LearningRate 0.000045
[Ep 82 it 29	 PSNR SIDD: 18.2539	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 82 it 59	 PSNR SIDD: 18.0371	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 82 it 89	 PSNR SIDD: 18.1820	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 82 it 119	 PSNR SIDD: 18.3949	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 82	Time: 13.6572	Loss: 23.9499	LearningRate 0.000044
[Ep 83 it 29	 PSNR SIDD: 17.9241	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 83 it 59	 PSNR SIDD: 18.5756	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 83 it 89	 PSNR SIDD: 18.1578	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 83 it 119	 PSNR SIDD: 18.5776	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 83	Time: 13.4916	Loss: 23.3374	LearningRate 0.000043
[Ep 84 it 29	 PSNR SIDD: 18.2157	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 84 it 59	 PSNR SIDD: 18.4365	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 84 it 89	 PSNR SIDD: 18.1641	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 84 it 119	 PSNR SIDD: 18.5298	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 84	Time: 14.1513	Loss: 24.0568	LearningRate 0.000042
[Ep 85 it 29	 PSNR SIDD: 18.4455	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 85 it 59	 PSNR SIDD: 17.9989	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 85 it 89	 PSNR SIDD: 18.2937	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 85 it 119	 PSNR SIDD: 18.1157	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 85	Time: 13.9587	Loss: 24.1352	LearningRate 0.000041
[Ep 86 it 29	 PSNR SIDD: 17.6248	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 86 it 59	 PSNR SIDD: 18.4796	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 86 it 89	 PSNR SIDD: 18.1446	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 86 it 119	 PSNR SIDD: 17.9542	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 86	Time: 12.7874	Loss: 23.2995	LearningRate 0.000040
[Ep 87 it 29	 PSNR SIDD: 18.2697	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 87 it 59	 PSNR SIDD: 17.9831	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 87 it 89	 PSNR SIDD: 17.8775	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 87 it 119	 PSNR SIDD: 18.5252	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 87	Time: 13.3923	Loss: 23.3847	LearningRate 0.000038
[Ep 88 it 29	 PSNR SIDD: 18.3539	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 88 it 59	 PSNR SIDD: 18.1351	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 88 it 89	 PSNR SIDD: 17.8661	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 88 it 119	 PSNR SIDD: 17.9372	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 88	Time: 13.4677	Loss: 24.6912	LearningRate 0.000037
[Ep 89 it 29	 PSNR SIDD: 18.1495	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 89 it 59	 PSNR SIDD: 18.1146	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 89 it 89	 PSNR SIDD: 18.6597	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 89 it 119	 PSNR SIDD: 18.4192	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 89	Time: 13.8382	Loss: 23.9512	LearningRate 0.000036
[Ep 90 it 29	 PSNR SIDD: 18.4344	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 90 it 59	 PSNR SIDD: 18.4508	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 90 it 89	 PSNR SIDD: 18.0503	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 90 it 119	 PSNR SIDD: 18.5921	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 90	Time: 13.3470	Loss: 23.6777	LearningRate 0.000035
[Ep 91 it 29	 PSNR SIDD: 18.1770	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 91 it 59	 PSNR SIDD: 18.4851	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 91 it 89	 PSNR SIDD: 18.4045	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 91 it 119	 PSNR SIDD: 18.2968	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 91	Time: 12.9889	Loss: 23.8465	LearningRate 0.000034
[Ep 92 it 29	 PSNR SIDD: 18.3663	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 92 it 59	 PSNR SIDD: 18.6048	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 92 it 89	 PSNR SIDD: 18.1939	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 92 it 119	 PSNR SIDD: 18.2800	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 92	Time: 13.3247	Loss: 23.2213	LearningRate 0.000033
[Ep 93 it 29	 PSNR SIDD: 18.2533	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 93 it 59	 PSNR SIDD: 18.0868	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 93 it 89	 PSNR SIDD: 18.2924	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 93 it 119	 PSNR SIDD: 18.4882	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 93	Time: 13.1389	Loss: 22.9682	LearningRate 0.000032
[Ep 94 it 29	 PSNR SIDD: 18.1076	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 94 it 59	 PSNR SIDD: 18.3802	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 94 it 89	 PSNR SIDD: 18.0785	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 94 it 119	 PSNR SIDD: 17.9830	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 94	Time: 13.2801	Loss: 22.6226	LearningRate 0.000031
[Ep 95 it 29	 PSNR SIDD: 18.4057	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 95 it 59	 PSNR SIDD: 18.2410	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 95 it 89	 PSNR SIDD: 18.3449	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 95 it 119	 PSNR SIDD: 18.3421	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 95	Time: 13.2735	Loss: 23.1842	LearningRate 0.000030
[Ep 96 it 29	 PSNR SIDD: 18.2303	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 96 it 59	 PSNR SIDD: 18.3060	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 96 it 89	 PSNR SIDD: 18.2838	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 96 it 119	 PSNR SIDD: 18.4089	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 96	Time: 13.9250	Loss: 22.7907	LearningRate 0.000030
[Ep 97 it 29	 PSNR SIDD: 17.8044	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 97 it 59	 PSNR SIDD: 18.4265	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 97 it 89	 PSNR SIDD: 18.5971	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 97 it 119	 PSNR SIDD: 18.0788	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 97	Time: 13.0217	Loss: 23.4633	LearningRate 0.000029
[Ep 98 it 29	 PSNR SIDD: 18.2790	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 98 it 59	 PSNR SIDD: 18.4875	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 98 it 89	 PSNR SIDD: 18.5207	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 98 it 119	 PSNR SIDD: 18.2027	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 98	Time: 13.4907	Loss: 23.3125	LearningRate 0.000028
[Ep 99 it 29	 PSNR SIDD: 18.3022	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 99 it 59	 PSNR SIDD: 18.3869	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 99 it 89	 PSNR SIDD: 18.2240	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 99 it 119	 PSNR SIDD: 18.5938	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 99	Time: 13.4703	Loss: 22.6426	LearningRate 0.000027
[Ep 100 it 29	 PSNR SIDD: 18.4740	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 100 it 59	 PSNR SIDD: 18.4516	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 100 it 89	 PSNR SIDD: 18.2477	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 100 it 119	 PSNR SIDD: 17.8625	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 100	Time: 12.8561	Loss: 23.0818	LearningRate 0.000026
[Ep 101 it 29	 PSNR SIDD: 18.5295	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 101 it 59	 PSNR SIDD: 18.1682	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 101 it 89	 PSNR SIDD: 18.1860	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 101 it 119	 PSNR SIDD: 18.4047	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 101	Time: 13.5507	Loss: 22.6269	LearningRate 0.000025
[Ep 102 it 29	 PSNR SIDD: 18.4697	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 102 it 59	 PSNR SIDD: 18.3720	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 102 it 89	 PSNR SIDD: 18.3016	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 102 it 119	 PSNR SIDD: 18.2181	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 102	Time: 13.5825	Loss: 23.1872	LearningRate 0.000024
[Ep 103 it 29	 PSNR SIDD: 17.7472	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 103 it 59	 PSNR SIDD: 18.1897	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 103 it 89	 PSNR SIDD: 18.4959	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 103 it 119	 PSNR SIDD: 18.2031	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 103	Time: 14.4324	Loss: 23.2416	LearningRate 0.000023
[Ep 104 it 29	 PSNR SIDD: 18.2587	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 104 it 59	 PSNR SIDD: 18.6086	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 104 it 89	 PSNR SIDD: 18.6682	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 104 it 119	 PSNR SIDD: 18.0501	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 104	Time: 13.8962	Loss: 22.7105	LearningRate 0.000022
[Ep 105 it 29	 PSNR SIDD: 18.4365	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 105 it 59	 PSNR SIDD: 18.5573	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 105 it 89	 PSNR SIDD: 18.5732	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 105 it 119	 PSNR SIDD: 18.2464	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 105	Time: 14.0976	Loss: 22.5029	LearningRate 0.000021
[Ep 106 it 29	 PSNR SIDD: 18.0705	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 106 it 59	 PSNR SIDD: 18.2476	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 106 it 89	 PSNR SIDD: 18.3969	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 106 it 119	 PSNR SIDD: 18.5870	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 106	Time: 14.0792	Loss: 23.1037	LearningRate 0.000020
[Ep 107 it 29	 PSNR SIDD: 18.0483	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 107 it 59	 PSNR SIDD: 18.6820	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 107 it 89	 PSNR SIDD: 18.6987	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 107 it 119	 PSNR SIDD: 18.2841	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 107	Time: 13.6601	Loss: 22.6045	LearningRate 0.000020
[Ep 108 it 29	 PSNR SIDD: 18.4082	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 108 it 59	 PSNR SIDD: 18.5401	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 108 it 89	 PSNR SIDD: 18.6075	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 108 it 119	 PSNR SIDD: 18.5168	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 108	Time: 13.5702	Loss: 22.2358	LearningRate 0.000019
[Ep 109 it 29	 PSNR SIDD: 18.7092	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 109 it 59	 PSNR SIDD: 18.5384	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 109 it 89	 PSNR SIDD: 18.5560	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 109 it 119	 PSNR SIDD: 18.2472	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 109	Time: 12.9201	Loss: 22.5246	LearningRate 0.000018
[Ep 110 it 29	 PSNR SIDD: 18.2913	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 110 it 59	 PSNR SIDD: 18.7410	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 110 it 89	 PSNR SIDD: 18.3872	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 110 it 119	 PSNR SIDD: 18.1067	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 110	Time: 13.7539	Loss: 22.5592	LearningRate 0.000017
[Ep 111 it 29	 PSNR SIDD: 18.5866	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 111 it 59	 PSNR SIDD: 18.1516	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 111 it 89	 PSNR SIDD: 18.5263	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 111 it 119	 PSNR SIDD: 18.4399	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 111	Time: 13.7376	Loss: 22.7138	LearningRate 0.000016
[Ep 112 it 29	 PSNR SIDD: 18.3598	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 112 it 59	 PSNR SIDD: 18.5396	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 112 it 89	 PSNR SIDD: 18.4952	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 112 it 119	 PSNR SIDD: 18.4198	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
Epoch: 112	Time: 12.8572	Loss: 22.1287	LearningRate 0.000016
[Ep 113 it 29	 PSNR SIDD: 18.4013	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 113 it 59	 PSNR SIDD: 18.4878	] ----  [best_Ep_SIDD 75 best_it_SIDD 119 Best_PSNR_SIDD 18.7493] 
[Ep 113 it 89	 PSNR SIDD: 18.8480	] ----  [best_Ep_SIDD 113 best_it_SIDD 89 Best_PSNR_SIDD 18.8480] 
[Ep 113 it 119	 PSNR SIDD: 18.6497	] ----  [best_Ep_SIDD 113 best_it_SIDD 89 Best_PSNR_SIDD 18.8480] 
Epoch: 113	Time: 15.0700	Loss: 22.6576	LearningRate 0.000015
[Ep 114 it 29	 PSNR SIDD: 18.3852	] ----  [best_Ep_SIDD 113 best_it_SIDD 89 Best_PSNR_SIDD 18.8480] 
[Ep 114 it 59	 PSNR SIDD: 18.4670	] ----  [best_Ep_SIDD 113 best_it_SIDD 89 Best_PSNR_SIDD 18.8480] 
[Ep 114 it 89	 PSNR SIDD: 18.8955	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 114 it 119	 PSNR SIDD: 18.6290	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
Epoch: 114	Time: 13.9532	Loss: 21.8250	LearningRate 0.000014
[Ep 115 it 29	 PSNR SIDD: 18.5394	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 115 it 59	 PSNR SIDD: 18.5709	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 115 it 89	 PSNR SIDD: 18.4825	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 115 it 119	 PSNR SIDD: 18.7414	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
Epoch: 115	Time: 13.6659	Loss: 22.0657	LearningRate 0.000014
[Ep 116 it 29	 PSNR SIDD: 18.6787	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 116 it 59	 PSNR SIDD: 18.6263	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 116 it 89	 PSNR SIDD: 18.4850	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 116 it 119	 PSNR SIDD: 18.2820	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
Epoch: 116	Time: 13.6305	Loss: 21.2513	LearningRate 0.000013
[Ep 117 it 29	 PSNR SIDD: 18.4508	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 117 it 59	 PSNR SIDD: 18.5158	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 117 it 89	 PSNR SIDD: 18.7730	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 117 it 119	 PSNR SIDD: 18.5590	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
Epoch: 117	Time: 13.7821	Loss: 22.1345	LearningRate 0.000012
[Ep 118 it 29	 PSNR SIDD: 18.5478	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 118 it 59	 PSNR SIDD: 18.5813	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 118 it 89	 PSNR SIDD: 18.7258	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 118 it 119	 PSNR SIDD: 18.7470	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
Epoch: 118	Time: 13.3256	Loss: 21.8389	LearningRate 0.000011
[Ep 119 it 29	 PSNR SIDD: 18.6462	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 119 it 59	 PSNR SIDD: 18.8137	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 119 it 89	 PSNR SIDD: 18.6810	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 119 it 119	 PSNR SIDD: 18.8698	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
Epoch: 119	Time: 13.2708	Loss: 21.7062	LearningRate 0.000011
[Ep 120 it 29	 PSNR SIDD: 18.8639	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 120 it 59	 PSNR SIDD: 18.6440	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 120 it 89	 PSNR SIDD: 18.7426	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 120 it 119	 PSNR SIDD: 18.6454	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
Epoch: 120	Time: 14.0432	Loss: 21.6563	LearningRate 0.000010
[Ep 121 it 29	 PSNR SIDD: 18.2483	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 121 it 59	 PSNR SIDD: 18.6678	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 121 it 89	 PSNR SIDD: 18.7921	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 121 it 119	 PSNR SIDD: 18.5952	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
Epoch: 121	Time: 13.7568	Loss: 21.9913	LearningRate 0.000010
[Ep 122 it 29	 PSNR SIDD: 18.4870	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 122 it 59	 PSNR SIDD: 18.5773	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 122 it 89	 PSNR SIDD: 18.5861	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 122 it 119	 PSNR SIDD: 18.7298	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
Epoch: 122	Time: 14.2028	Loss: 21.9154	LearningRate 0.000009
[Ep 123 it 29	 PSNR SIDD: 18.5920	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 123 it 59	 PSNR SIDD: 18.5920	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 123 it 89	 PSNR SIDD: 18.6586	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 123 it 119	 PSNR SIDD: 18.6774	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
Epoch: 123	Time: 13.6817	Loss: 21.8886	LearningRate 0.000008
[Ep 124 it 29	 PSNR SIDD: 18.6416	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 124 it 59	 PSNR SIDD: 18.6636	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 124 it 89	 PSNR SIDD: 18.6349	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 124 it 119	 PSNR SIDD: 18.7735	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
Epoch: 124	Time: 13.5893	Loss: 21.7489	LearningRate 0.000008
[Ep 125 it 29	 PSNR SIDD: 18.5766	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 125 it 59	 PSNR SIDD: 18.6700	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 125 it 89	 PSNR SIDD: 18.3755	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
[Ep 125 it 119	 PSNR SIDD: 18.6590	] ----  [best_Ep_SIDD 114 best_it_SIDD 89 Best_PSNR_SIDD 18.8955] 
Epoch: 125	Time: 13.1269	Loss: 21.7425	LearningRate 0.000007
[Ep 126 it 29	 PSNR SIDD: 18.9008	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 126 it 59	 PSNR SIDD: 18.8202	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 126 it 89	 PSNR SIDD: 18.6575	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 126 it 119	 PSNR SIDD: 18.5002	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 126	Time: 14.2641	Loss: 21.8445	LearningRate 0.000007
[Ep 127 it 29	 PSNR SIDD: 18.6885	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 127 it 59	 PSNR SIDD: 18.5613	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 127 it 89	 PSNR SIDD: 18.7647	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 127 it 119	 PSNR SIDD: 18.5997	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 127	Time: 13.8240	Loss: 21.7161	LearningRate 0.000006
[Ep 128 it 29	 PSNR SIDD: 18.7869	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 128 it 59	 PSNR SIDD: 18.4807	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 128 it 89	 PSNR SIDD: 18.7122	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 128 it 119	 PSNR SIDD: 18.3602	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 128	Time: 13.6422	Loss: 21.1638	LearningRate 0.000006
[Ep 129 it 29	 PSNR SIDD: 18.6431	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 129 it 59	 PSNR SIDD: 18.6145	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 129 it 89	 PSNR SIDD: 18.5937	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 129 it 119	 PSNR SIDD: 18.7952	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 129	Time: 13.1027	Loss: 21.8639	LearningRate 0.000005
[Ep 130 it 29	 PSNR SIDD: 18.6507	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 130 it 59	 PSNR SIDD: 18.6034	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 130 it 89	 PSNR SIDD: 18.5408	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 130 it 119	 PSNR SIDD: 18.8659	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 130	Time: 13.4900	Loss: 21.7655	LearningRate 0.000005
[Ep 131 it 29	 PSNR SIDD: 18.6851	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 131 it 59	 PSNR SIDD: 18.5101	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 131 it 89	 PSNR SIDD: 18.7220	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 131 it 119	 PSNR SIDD: 18.7763	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 131	Time: 13.1552	Loss: 22.0499	LearningRate 0.000005
[Ep 132 it 29	 PSNR SIDD: 18.5002	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 132 it 59	 PSNR SIDD: 18.6283	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 132 it 89	 PSNR SIDD: 18.5138	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 132 it 119	 PSNR SIDD: 18.5619	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 132	Time: 13.7416	Loss: 21.7326	LearningRate 0.000004
[Ep 133 it 29	 PSNR SIDD: 18.5902	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 133 it 59	 PSNR SIDD: 18.6417	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 133 it 89	 PSNR SIDD: 18.7524	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 133 it 119	 PSNR SIDD: 18.6332	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 133	Time: 13.6449	Loss: 21.8612	LearningRate 0.000004
[Ep 134 it 29	 PSNR SIDD: 18.6703	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 134 it 59	 PSNR SIDD: 18.7574	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 134 it 89	 PSNR SIDD: 18.6505	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 134 it 119	 PSNR SIDD: 18.5777	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 134	Time: 14.1196	Loss: 20.5610	LearningRate 0.000004
[Ep 135 it 29	 PSNR SIDD: 18.4471	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 135 it 59	 PSNR SIDD: 18.6361	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 135 it 89	 PSNR SIDD: 18.4722	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 135 it 119	 PSNR SIDD: 18.8100	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 135	Time: 13.7466	Loss: 21.7914	LearningRate 0.000003
[Ep 136 it 29	 PSNR SIDD: 18.8518	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 136 it 59	 PSNR SIDD: 18.7321	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 136 it 89	 PSNR SIDD: 18.5391	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 136 it 119	 PSNR SIDD: 18.6414	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 136	Time: 13.7307	Loss: 22.1991	LearningRate 0.000003
[Ep 137 it 29	 PSNR SIDD: 18.6785	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 137 it 59	 PSNR SIDD: 18.7062	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 137 it 89	 PSNR SIDD: 18.5355	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 137 it 119	 PSNR SIDD: 18.7090	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 137	Time: 13.0444	Loss: 21.3579	LearningRate 0.000003
[Ep 138 it 29	 PSNR SIDD: 18.5580	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 138 it 59	 PSNR SIDD: 18.7075	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 138 it 89	 PSNR SIDD: 18.5602	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 138 it 119	 PSNR SIDD: 18.6581	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 138	Time: 13.9347	Loss: 21.5862	LearningRate 0.000002
[Ep 139 it 29	 PSNR SIDD: 18.6345	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 139 it 59	 PSNR SIDD: 18.7775	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 139 it 89	 PSNR SIDD: 18.6104	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 139 it 119	 PSNR SIDD: 18.6569	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 139	Time: 13.7501	Loss: 21.6071	LearningRate 0.000002
[Ep 140 it 29	 PSNR SIDD: 18.6430	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 140 it 59	 PSNR SIDD: 18.6326	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 140 it 89	 PSNR SIDD: 18.6516	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 140 it 119	 PSNR SIDD: 18.6320	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 140	Time: 13.5198	Loss: 21.9535	LearningRate 0.000002
[Ep 141 it 29	 PSNR SIDD: 18.7378	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 141 it 59	 PSNR SIDD: 18.6004	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 141 it 89	 PSNR SIDD: 18.7363	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 141 it 119	 PSNR SIDD: 18.7619	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 141	Time: 13.7735	Loss: 21.4398	LearningRate 0.000002
[Ep 142 it 29	 PSNR SIDD: 18.6936	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 142 it 59	 PSNR SIDD: 18.6624	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 142 it 89	 PSNR SIDD: 18.7379	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 142 it 119	 PSNR SIDD: 18.6534	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 142	Time: 12.8637	Loss: 21.6206	LearningRate 0.000002
[Ep 143 it 29	 PSNR SIDD: 18.7691	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 143 it 59	 PSNR SIDD: 18.7729	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 143 it 89	 PSNR SIDD: 18.7352	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 143 it 119	 PSNR SIDD: 18.5328	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 143	Time: 12.6861	Loss: 21.6651	LearningRate 0.000001
[Ep 144 it 29	 PSNR SIDD: 18.7509	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 144 it 59	 PSNR SIDD: 18.7533	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 144 it 89	 PSNR SIDD: 18.6255	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 144 it 119	 PSNR SIDD: 18.6806	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 144	Time: 14.5279	Loss: 21.0047	LearningRate 0.000001
[Ep 145 it 29	 PSNR SIDD: 18.7453	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 145 it 59	 PSNR SIDD: 18.6708	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 145 it 89	 PSNR SIDD: 18.7248	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 145 it 119	 PSNR SIDD: 18.7133	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 145	Time: 13.9251	Loss: 21.6883	LearningRate 0.000001
[Ep 146 it 29	 PSNR SIDD: 18.6973	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 146 it 59	 PSNR SIDD: 18.6775	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 146 it 89	 PSNR SIDD: 18.6574	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 146 it 119	 PSNR SIDD: 18.6464	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 146	Time: 13.4696	Loss: 21.3541	LearningRate 0.000001
[Ep 147 it 29	 PSNR SIDD: 18.6952	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 147 it 59	 PSNR SIDD: 18.6891	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 147 it 89	 PSNR SIDD: 18.7246	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 147 it 119	 PSNR SIDD: 18.7012	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 147	Time: 12.9862	Loss: 21.5825	LearningRate 0.000001
[Ep 148 it 29	 PSNR SIDD: 18.6621	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 148 it 59	 PSNR SIDD: 18.6576	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 148 it 89	 PSNR SIDD: 18.6503	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 148 it 119	 PSNR SIDD: 18.7059	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 148	Time: 13.7884	Loss: 21.4458	LearningRate 0.000001
[Ep 149 it 29	 PSNR SIDD: 18.7698	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 149 it 59	 PSNR SIDD: 18.6475	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 149 it 89	 PSNR SIDD: 18.6500	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 149 it 119	 PSNR SIDD: 18.7224	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 149	Time: 13.8415	Loss: 21.5786	LearningRate 0.000001
[Ep 150 it 29	 PSNR SIDD: 18.7676	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 150 it 59	 PSNR SIDD: 18.7020	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 150 it 89	 PSNR SIDD: 18.7110	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
[Ep 150 it 119	 PSNR SIDD: 18.6627	] ----  [best_Ep_SIDD 126 best_it_SIDD 29 Best_PSNR_SIDD 18.9008] 
Epoch: 150	Time: 13.6366	Loss: 21.7163	LearningRate 0.000001
