Namespace(arch='Uformer', att_se=False, batch_size=32, checkpoint=50, dataset='SIDD', embed_dim=32, env='32_1006_1_0', eval_workers=8, global_skip=False, gpu='0', local_skip=False, lr_initial=0.0002, mode='denoising', nepoch=150, norm_layer='nn.LayerNorm', optimizer='adamw', pretrain_weights='./log/Uformer32/models/model_best.pth', resume=False, save_dir='/home/ma-user/work/deNoTr/log', save_images=False, token_mlp='leff', token_projection='linear', train_dir='/home/mist/lowlight/datasets/lol_stage0/train', train_ps=64, train_workers=16, val_dir='/home/mist/lowlight/datasets/lol_stage0/valid', vit_depth=12, vit_dim=256, vit_mlp_dim=512, vit_nheads=8, vit_patch_size=16, vit_share=False, warmup=True, warmup_epochs=3, weight_decay=0.02, win_size=8)
Uformer(
  embed_dim=32, token_projection=linear, token_mlp=leff,win_size=8
  (pos_drop): Dropout(p=0.0, inplace=False)
  (input_proj): InputProj(
    (proj): Sequential(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
  (output_proj): OutputProj(
    (proj): Sequential(
      (0): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (encoderlayer_0): BasicUformerLayer(
    dim=32, input_resolution=(64, 64), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=32, input_resolution=(64, 64), num_heads=1, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=32, win_size=(8, 8), num_heads=1
          (qkv): LinearProjection(
            (to_q): Linear(in_features=32, out_features=32, bias=True)
            (to_kv): Linear(in_features=32, out_features=64, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=32, out_features=32, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=32, out_features=128, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=128, out_features=32, bias=True)
          )
        )
      )
      (1): LeWinTransformerBlock(
        dim=32, input_resolution=(64, 64), num_heads=1, win_size=8, shift_size=4, mlp_ratio=4.0
        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=32, win_size=(8, 8), num_heads=1
          (qkv): LinearProjection(
            (to_q): Linear(in_features=32, out_features=32, bias=True)
            (to_kv): Linear(in_features=32, out_features=64, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=32, out_features=32, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=32, out_features=128, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=128, out_features=32, bias=True)
          )
        )
      )
    )
  )
  (skipconnection_0): BasicUformerLayer(
    dim=32, input_resolution=(64, 64), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=32, input_resolution=(64, 64), num_heads=1, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=32, win_size=(8, 8), num_heads=1
          (qkv): LinearProjection(
            (to_q): Linear(in_features=32, out_features=32, bias=True)
            (to_kv): Linear(in_features=32, out_features=64, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=32, out_features=32, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=32, out_features=128, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=128, out_features=32, bias=True)
          )
        )
      )
      (1): LeWinTransformerBlock(
        dim=32, input_resolution=(64, 64), num_heads=1, win_size=8, shift_size=4, mlp_ratio=4.0
        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=32, win_size=(8, 8), num_heads=1
          (qkv): LinearProjection(
            (to_q): Linear(in_features=32, out_features=32, bias=True)
            (to_kv): Linear(in_features=32, out_features=64, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=32, out_features=32, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=32, out_features=128, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=128, out_features=32, bias=True)
          )
        )
      )
    )
  )
  (dowsample_0): Downsample(
    (conv): Sequential(
      (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (encoderlayer_1): BasicUformerLayer(
    dim=64, input_resolution=(32, 32), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=64, input_resolution=(32, 32), num_heads=2, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=64, win_size=(8, 8), num_heads=2
          (qkv): LinearProjection(
            (to_q): Linear(in_features=64, out_features=64, bias=True)
            (to_kv): Linear(in_features=64, out_features=128, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=64, out_features=256, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=256, out_features=64, bias=True)
          )
        )
      )
      (1): LeWinTransformerBlock(
        dim=64, input_resolution=(32, 32), num_heads=2, win_size=8, shift_size=4, mlp_ratio=4.0
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=64, win_size=(8, 8), num_heads=2
          (qkv): LinearProjection(
            (to_q): Linear(in_features=64, out_features=64, bias=True)
            (to_kv): Linear(in_features=64, out_features=128, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=64, out_features=256, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=256, out_features=64, bias=True)
          )
        )
      )
    )
  )
  (skipconnection_1): BasicUformerLayer(
    dim=64, input_resolution=(32, 32), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=64, input_resolution=(32, 32), num_heads=2, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=64, win_size=(8, 8), num_heads=2
          (qkv): LinearProjection(
            (to_q): Linear(in_features=64, out_features=64, bias=True)
            (to_kv): Linear(in_features=64, out_features=128, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=64, out_features=256, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=256, out_features=64, bias=True)
          )
        )
      )
      (1): LeWinTransformerBlock(
        dim=64, input_resolution=(32, 32), num_heads=2, win_size=8, shift_size=4, mlp_ratio=4.0
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=64, win_size=(8, 8), num_heads=2
          (qkv): LinearProjection(
            (to_q): Linear(in_features=64, out_features=64, bias=True)
            (to_kv): Linear(in_features=64, out_features=128, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=64, out_features=256, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=256, out_features=64, bias=True)
          )
        )
      )
    )
  )
  (dowsample_1): Downsample(
    (conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (encoderlayer_2): BasicUformerLayer(
    dim=128, input_resolution=(16, 16), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=128, input_resolution=(16, 16), num_heads=4, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=128, win_size=(8, 8), num_heads=4
          (qkv): LinearProjection(
            (to_q): Linear(in_features=128, out_features=128, bias=True)
            (to_kv): Linear(in_features=128, out_features=256, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=128, out_features=512, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=512, out_features=128, bias=True)
          )
        )
      )
      (1): LeWinTransformerBlock(
        dim=128, input_resolution=(16, 16), num_heads=4, win_size=8, shift_size=4, mlp_ratio=4.0
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=128, win_size=(8, 8), num_heads=4
          (qkv): LinearProjection(
            (to_q): Linear(in_features=128, out_features=128, bias=True)
            (to_kv): Linear(in_features=128, out_features=256, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=128, out_features=512, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=512, out_features=128, bias=True)
          )
        )
      )
    )
  )
  (skipconnection_2): BasicUformerLayer(
    dim=128, input_resolution=(16, 16), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=128, input_resolution=(16, 16), num_heads=4, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=128, win_size=(8, 8), num_heads=4
          (qkv): LinearProjection(
            (to_q): Linear(in_features=128, out_features=128, bias=True)
            (to_kv): Linear(in_features=128, out_features=256, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=128, out_features=512, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=512, out_features=128, bias=True)
          )
        )
      )
      (1): LeWinTransformerBlock(
        dim=128, input_resolution=(16, 16), num_heads=4, win_size=8, shift_size=4, mlp_ratio=4.0
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=128, win_size=(8, 8), num_heads=4
          (qkv): LinearProjection(
            (to_q): Linear(in_features=128, out_features=128, bias=True)
            (to_kv): Linear(in_features=128, out_features=256, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=128, out_features=512, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=512, out_features=128, bias=True)
          )
        )
      )
    )
  )
  (dowsample_2): Downsample(
    (conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (encoderlayer_3): BasicUformerLayer(
    dim=256, input_resolution=(8, 8), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=256, input_resolution=(8, 8), num_heads=8, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
        )
      )
      (1): LeWinTransformerBlock(
        dim=256, input_resolution=(8, 8), num_heads=8, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
        )
      )
    )
  )
  (skipconnection_3): BasicUformerLayer(
    dim=256, input_resolution=(8, 8), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=256, input_resolution=(8, 8), num_heads=8, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
        )
      )
      (1): LeWinTransformerBlock(
        dim=256, input_resolution=(8, 8), num_heads=8, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
        )
      )
    )
  )
  (dowsample_3): Downsample(
    (conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (resize_0): Upsample(
    (deconv): Sequential(
      (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (resize_1): Upsample(
    (deconv): Sequential(
      (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (resize_2): Upsample(
    (deconv): Sequential(
      (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (resize_3): Upsample(
    (deconv): Sequential(
      (0): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (resize_4): OutputProj(
    (proj): Sequential(
      (0): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (recover_0): InputProj(
    (proj): Sequential(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
  (conv): BasicUformerLayer(
    dim=32, input_resolution=(64, 64), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=32, input_resolution=(64, 64), num_heads=16, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=32, win_size=(8, 8), num_heads=16
          (qkv): LinearProjection(
            (to_q): Linear(in_features=32, out_features=32, bias=True)
            (to_kv): Linear(in_features=32, out_features=64, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=32, out_features=32, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=32, out_features=128, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=128, out_features=32, bias=True)
          )
        )
      )
      (1): LeWinTransformerBlock(
        dim=32, input_resolution=(64, 64), num_heads=16, win_size=8, shift_size=4, mlp_ratio=4.0
        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=32, win_size=(8, 8), num_heads=16
          (qkv): LinearProjection(
            (to_q): Linear(in_features=32, out_features=32, bias=True)
            (to_kv): Linear(in_features=32, out_features=64, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=32, out_features=32, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=32, out_features=128, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=128, out_features=32, bias=True)
          )
        )
      )
    )
  )
  (recover_1): Downsample(
    (conv): Sequential(
      (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (recover_2): Downsample(
    (conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (recover_3): Downsample(
    (conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (recover_4): Downsample(
    (conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (upsample_0): Upsample(
    (deconv): Sequential(
      (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (decoderlayer_0): BasicUformerLayer(
    dim=512, input_resolution=(8, 8), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=512, input_resolution=(8, 8), num_heads=16, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=512, win_size=(8, 8), num_heads=16
          (qkv): LinearProjection(
            (to_q): Linear(in_features=512, out_features=512, bias=True)
            (to_kv): Linear(in_features=512, out_features=1024, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=512, out_features=2048, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
      )
      (1): LeWinTransformerBlock(
        dim=512, input_resolution=(8, 8), num_heads=16, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=512, win_size=(8, 8), num_heads=16
          (qkv): LinearProjection(
            (to_q): Linear(in_features=512, out_features=512, bias=True)
            (to_kv): Linear(in_features=512, out_features=1024, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=512, out_features=2048, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
      )
    )
  )
  (upsample_1): Upsample(
    (deconv): Sequential(
      (0): ConvTranspose2d(512, 128, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (decoderlayer_1): BasicUformerLayer(
    dim=256, input_resolution=(16, 16), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=256, input_resolution=(16, 16), num_heads=8, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
        )
      )
      (1): LeWinTransformerBlock(
        dim=256, input_resolution=(16, 16), num_heads=8, win_size=8, shift_size=4, mlp_ratio=4.0
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
        )
      )
    )
  )
  (upsample_2): Upsample(
    (deconv): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (decoderlayer_2): BasicUformerLayer(
    dim=128, input_resolution=(32, 32), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=128, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=128, win_size=(8, 8), num_heads=4
          (qkv): LinearProjection(
            (to_q): Linear(in_features=128, out_features=128, bias=True)
            (to_kv): Linear(in_features=128, out_features=256, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=128, out_features=512, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=512, out_features=128, bias=True)
          )
        )
      )
      (1): LeWinTransformerBlock(
        dim=128, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=4, mlp_ratio=4.0
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=128, win_size=(8, 8), num_heads=4
          (qkv): LinearProjection(
            (to_q): Linear(in_features=128, out_features=128, bias=True)
            (to_kv): Linear(in_features=128, out_features=256, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=128, out_features=512, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=512, out_features=128, bias=True)
          )
        )
      )
    )
  )
  (upsample_3): Upsample(
    (deconv): Sequential(
      (0): ConvTranspose2d(128, 32, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (decoderlayer_3): BasicUformerLayer(
    dim=64, input_resolution=(64, 64), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=64, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=0, mlp_ratio=4.0
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=64, win_size=(8, 8), num_heads=2
          (qkv): LinearProjection(
            (to_q): Linear(in_features=64, out_features=64, bias=True)
            (to_kv): Linear(in_features=64, out_features=128, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=64, out_features=256, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=256, out_features=64, bias=True)
          )
        )
      )
      (1): LeWinTransformerBlock(
        dim=64, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=4, mlp_ratio=4.0
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=64, win_size=(8, 8), num_heads=2
          (qkv): LinearProjection(
            (to_q): Linear(in_features=64, out_features=64, bias=True)
            (to_kv): Linear(in_features=64, out_features=128, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (se_layer): Identity()
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=64, out_features=256, bias=True)
            (1): GELU()
          )
          (dwconv): Sequential(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (1): GELU()
          )
          (linear2): Sequential(
            (0): Linear(in_features=256, out_features=64, bias=True)
          )
        )
      )
    )
  )
)
[Ep 1 it 29	 PSNR SIDD: 10.9417	] ----  [best_Ep_SIDD 1 best_it_SIDD 29 Best_PSNR_SIDD 10.9417] 
[Ep 1 it 59	 PSNR SIDD: 13.0943	] ----  [best_Ep_SIDD 1 best_it_SIDD 59 Best_PSNR_SIDD 13.0943] 
[Ep 1 it 89	 PSNR SIDD: 13.8545	] ----  [best_Ep_SIDD 1 best_it_SIDD 89 Best_PSNR_SIDD 13.8545] 
[Ep 1 it 119	 PSNR SIDD: 14.4382	] ----  [best_Ep_SIDD 1 best_it_SIDD 119 Best_PSNR_SIDD 14.4382] 
Epoch: 1	Time: 27.6201	Loss: 22.9658	LearningRate 0.000133
[Ep 2 it 29	 PSNR SIDD: 14.4585	] ----  [best_Ep_SIDD 2 best_it_SIDD 29 Best_PSNR_SIDD 14.4585] 
[Ep 2 it 59	 PSNR SIDD: 14.6838	] ----  [best_Ep_SIDD 2 best_it_SIDD 59 Best_PSNR_SIDD 14.6838] 
[Ep 2 it 89	 PSNR SIDD: 14.8089	] ----  [best_Ep_SIDD 2 best_it_SIDD 89 Best_PSNR_SIDD 14.8089] 
[Ep 2 it 119	 PSNR SIDD: 14.5587	] ----  [best_Ep_SIDD 2 best_it_SIDD 89 Best_PSNR_SIDD 14.8089] 
Epoch: 2	Time: 26.8332	Loss: 6.9386	LearningRate 0.000200
[Ep 3 it 29	 PSNR SIDD: 15.0140	] ----  [best_Ep_SIDD 3 best_it_SIDD 29 Best_PSNR_SIDD 15.0140] 
[Ep 3 it 59	 PSNR SIDD: 14.4140	] ----  [best_Ep_SIDD 3 best_it_SIDD 29 Best_PSNR_SIDD 15.0140] 
[Ep 3 it 89	 PSNR SIDD: 14.6521	] ----  [best_Ep_SIDD 3 best_it_SIDD 29 Best_PSNR_SIDD 15.0140] 
[Ep 3 it 119	 PSNR SIDD: 15.4963	] ----  [best_Ep_SIDD 3 best_it_SIDD 119 Best_PSNR_SIDD 15.4963] 
Epoch: 3	Time: 26.8278	Loss: 6.0925	LearningRate 0.000200
[Ep 4 it 29	 PSNR SIDD: 15.2305	] ----  [best_Ep_SIDD 3 best_it_SIDD 119 Best_PSNR_SIDD 15.4963] 
[Ep 4 it 59	 PSNR SIDD: 14.8913	] ----  [best_Ep_SIDD 3 best_it_SIDD 119 Best_PSNR_SIDD 15.4963] 
[Ep 4 it 89	 PSNR SIDD: 15.3258	] ----  [best_Ep_SIDD 3 best_it_SIDD 119 Best_PSNR_SIDD 15.4963] 
[Ep 4 it 119	 PSNR SIDD: 15.9840	] ----  [best_Ep_SIDD 4 best_it_SIDD 119 Best_PSNR_SIDD 15.9840] 
Epoch: 4	Time: 25.5138	Loss: 5.2379	LearningRate 0.000200
[Ep 5 it 29	 PSNR SIDD: 15.2791	] ----  [best_Ep_SIDD 4 best_it_SIDD 119 Best_PSNR_SIDD 15.9840] 
[Ep 5 it 59	 PSNR SIDD: 16.0580	] ----  [best_Ep_SIDD 5 best_it_SIDD 59 Best_PSNR_SIDD 16.0580] 
[Ep 5 it 89	 PSNR SIDD: 15.8805	] ----  [best_Ep_SIDD 5 best_it_SIDD 59 Best_PSNR_SIDD 16.0580] 
[Ep 5 it 119	 PSNR SIDD: 16.1524	] ----  [best_Ep_SIDD 5 best_it_SIDD 119 Best_PSNR_SIDD 16.1524] 
Epoch: 5	Time: 26.1653	Loss: 4.4890	LearningRate 0.000200
[Ep 6 it 29	 PSNR SIDD: 16.0209	] ----  [best_Ep_SIDD 5 best_it_SIDD 119 Best_PSNR_SIDD 16.1524] 
[Ep 6 it 59	 PSNR SIDD: 16.3092	] ----  [best_Ep_SIDD 6 best_it_SIDD 59 Best_PSNR_SIDD 16.3092] 
[Ep 6 it 89	 PSNR SIDD: 15.7659	] ----  [best_Ep_SIDD 6 best_it_SIDD 59 Best_PSNR_SIDD 16.3092] 
[Ep 6 it 119	 PSNR SIDD: 15.7367	] ----  [best_Ep_SIDD 6 best_it_SIDD 59 Best_PSNR_SIDD 16.3092] 
Epoch: 6	Time: 25.9454	Loss: 3.2475	LearningRate 0.000200
[Ep 7 it 29	 PSNR SIDD: 16.4153	] ----  [best_Ep_SIDD 7 best_it_SIDD 29 Best_PSNR_SIDD 16.4153] 
[Ep 7 it 59	 PSNR SIDD: 16.1751	] ----  [best_Ep_SIDD 7 best_it_SIDD 29 Best_PSNR_SIDD 16.4153] 
[Ep 7 it 89	 PSNR SIDD: 15.8231	] ----  [best_Ep_SIDD 7 best_it_SIDD 29 Best_PSNR_SIDD 16.4153] 
[Ep 7 it 119	 PSNR SIDD: 16.3627	] ----  [best_Ep_SIDD 7 best_it_SIDD 29 Best_PSNR_SIDD 16.4153] 
Epoch: 7	Time: 25.1594	Loss: 3.1343	LearningRate 0.000199
[Ep 8 it 29	 PSNR SIDD: 16.6388	] ----  [best_Ep_SIDD 8 best_it_SIDD 29 Best_PSNR_SIDD 16.6388] 
[Ep 8 it 59	 PSNR SIDD: 16.2877	] ----  [best_Ep_SIDD 8 best_it_SIDD 29 Best_PSNR_SIDD 16.6388] 
[Ep 8 it 89	 PSNR SIDD: 16.6991	] ----  [best_Ep_SIDD 8 best_it_SIDD 89 Best_PSNR_SIDD 16.6991] 
[Ep 8 it 119	 PSNR SIDD: 16.4630	] ----  [best_Ep_SIDD 8 best_it_SIDD 89 Best_PSNR_SIDD 16.6991] 
Epoch: 8	Time: 27.5680	Loss: 3.1467	LearningRate 0.000199
[Ep 9 it 29	 PSNR SIDD: 16.5869	] ----  [best_Ep_SIDD 8 best_it_SIDD 89 Best_PSNR_SIDD 16.6991] 
[Ep 9 it 59	 PSNR SIDD: 16.3780	] ----  [best_Ep_SIDD 8 best_it_SIDD 89 Best_PSNR_SIDD 16.6991] 
[Ep 9 it 89	 PSNR SIDD: 16.4995	] ----  [best_Ep_SIDD 8 best_it_SIDD 89 Best_PSNR_SIDD 16.6991] 
[Ep 9 it 119	 PSNR SIDD: 16.3911	] ----  [best_Ep_SIDD 8 best_it_SIDD 89 Best_PSNR_SIDD 16.6991] 
Epoch: 9	Time: 25.6929	Loss: 3.1689	LearningRate 0.000199
[Ep 10 it 29	 PSNR SIDD: 15.1329	] ----  [best_Ep_SIDD 8 best_it_SIDD 89 Best_PSNR_SIDD 16.6991] 
[Ep 10 it 59	 PSNR SIDD: 16.6322	] ----  [best_Ep_SIDD 8 best_it_SIDD 89 Best_PSNR_SIDD 16.6991] 
[Ep 10 it 89	 PSNR SIDD: 16.9404	] ----  [best_Ep_SIDD 10 best_it_SIDD 89 Best_PSNR_SIDD 16.9404] 
[Ep 10 it 119	 PSNR SIDD: 16.7622	] ----  [best_Ep_SIDD 10 best_it_SIDD 89 Best_PSNR_SIDD 16.9404] 
Epoch: 10	Time: 25.1653	Loss: 2.9033	LearningRate 0.000199
[Ep 11 it 29	 PSNR SIDD: 16.8959	] ----  [best_Ep_SIDD 10 best_it_SIDD 89 Best_PSNR_SIDD 16.9404] 
[Ep 11 it 59	 PSNR SIDD: 15.3653	] ----  [best_Ep_SIDD 10 best_it_SIDD 89 Best_PSNR_SIDD 16.9404] 
[Ep 11 it 89	 PSNR SIDD: 16.2643	] ----  [best_Ep_SIDD 10 best_it_SIDD 89 Best_PSNR_SIDD 16.9404] 
[Ep 11 it 119	 PSNR SIDD: 15.7043	] ----  [best_Ep_SIDD 10 best_it_SIDD 89 Best_PSNR_SIDD 16.9404] 
Epoch: 11	Time: 25.9212	Loss: 3.0149	LearningRate 0.000198
[Ep 12 it 29	 PSNR SIDD: 16.2300	] ----  [best_Ep_SIDD 10 best_it_SIDD 89 Best_PSNR_SIDD 16.9404] 
[Ep 12 it 59	 PSNR SIDD: 16.7604	] ----  [best_Ep_SIDD 10 best_it_SIDD 89 Best_PSNR_SIDD 16.9404] 
[Ep 12 it 89	 PSNR SIDD: 16.3034	] ----  [best_Ep_SIDD 10 best_it_SIDD 89 Best_PSNR_SIDD 16.9404] 
[Ep 12 it 119	 PSNR SIDD: 16.3633	] ----  [best_Ep_SIDD 10 best_it_SIDD 89 Best_PSNR_SIDD 16.9404] 
Epoch: 12	Time: 25.5109	Loss: 2.8201	LearningRate 0.000198
[Ep 13 it 29	 PSNR SIDD: 16.5878	] ----  [best_Ep_SIDD 10 best_it_SIDD 89 Best_PSNR_SIDD 16.9404] 
[Ep 13 it 59	 PSNR SIDD: 15.7816	] ----  [best_Ep_SIDD 10 best_it_SIDD 89 Best_PSNR_SIDD 16.9404] 
[Ep 13 it 89	 PSNR SIDD: 16.3886	] ----  [best_Ep_SIDD 10 best_it_SIDD 89 Best_PSNR_SIDD 16.9404] 
[Ep 13 it 119	 PSNR SIDD: 16.9731	] ----  [best_Ep_SIDD 13 best_it_SIDD 119 Best_PSNR_SIDD 16.9731] 
Epoch: 13	Time: 26.4167	Loss: 2.8835	LearningRate 0.000197
[Ep 14 it 29	 PSNR SIDD: 16.1040	] ----  [best_Ep_SIDD 13 best_it_SIDD 119 Best_PSNR_SIDD 16.9731] 
[Ep 14 it 59	 PSNR SIDD: 16.5679	] ----  [best_Ep_SIDD 13 best_it_SIDD 119 Best_PSNR_SIDD 16.9731] 
[Ep 14 it 89	 PSNR SIDD: 16.7222	] ----  [best_Ep_SIDD 13 best_it_SIDD 119 Best_PSNR_SIDD 16.9731] 
[Ep 14 it 119	 PSNR SIDD: 16.8781	] ----  [best_Ep_SIDD 13 best_it_SIDD 119 Best_PSNR_SIDD 16.9731] 
Epoch: 14	Time: 24.5913	Loss: 2.7987	LearningRate 0.000197
[Ep 15 it 29	 PSNR SIDD: 16.9737	] ----  [best_Ep_SIDD 15 best_it_SIDD 29 Best_PSNR_SIDD 16.9737] 
[Ep 15 it 59	 PSNR SIDD: 16.4434	] ----  [best_Ep_SIDD 15 best_it_SIDD 29 Best_PSNR_SIDD 16.9737] 
[Ep 15 it 89	 PSNR SIDD: 17.2613	] ----  [best_Ep_SIDD 15 best_it_SIDD 89 Best_PSNR_SIDD 17.2613] 
[Ep 15 it 119	 PSNR SIDD: 16.7859	] ----  [best_Ep_SIDD 15 best_it_SIDD 89 Best_PSNR_SIDD 17.2613] 
Epoch: 15	Time: 26.3336	Loss: 2.7590	LearningRate 0.000196
[Ep 16 it 29	 PSNR SIDD: 15.7043	] ----  [best_Ep_SIDD 15 best_it_SIDD 89 Best_PSNR_SIDD 17.2613] 
[Ep 16 it 59	 PSNR SIDD: 16.5914	] ----  [best_Ep_SIDD 15 best_it_SIDD 89 Best_PSNR_SIDD 17.2613] 
[Ep 16 it 89	 PSNR SIDD: 16.8500	] ----  [best_Ep_SIDD 15 best_it_SIDD 89 Best_PSNR_SIDD 17.2613] 
[Ep 16 it 119	 PSNR SIDD: 16.1252	] ----  [best_Ep_SIDD 15 best_it_SIDD 89 Best_PSNR_SIDD 17.2613] 
Epoch: 16	Time: 25.5795	Loss: 2.7245	LearningRate 0.000196
[Ep 17 it 29	 PSNR SIDD: 17.1251	] ----  [best_Ep_SIDD 15 best_it_SIDD 89 Best_PSNR_SIDD 17.2613] 
[Ep 17 it 59	 PSNR SIDD: 17.2162	] ----  [best_Ep_SIDD 15 best_it_SIDD 89 Best_PSNR_SIDD 17.2613] 
[Ep 17 it 89	 PSNR SIDD: 16.9993	] ----  [best_Ep_SIDD 15 best_it_SIDD 89 Best_PSNR_SIDD 17.2613] 
[Ep 17 it 119	 PSNR SIDD: 17.0222	] ----  [best_Ep_SIDD 15 best_it_SIDD 89 Best_PSNR_SIDD 17.2613] 
Epoch: 17	Time: 25.4868	Loss: 2.8195	LearningRate 0.000195
[Ep 18 it 29	 PSNR SIDD: 16.9888	] ----  [best_Ep_SIDD 15 best_it_SIDD 89 Best_PSNR_SIDD 17.2613] 
[Ep 18 it 59	 PSNR SIDD: 16.9726	] ----  [best_Ep_SIDD 15 best_it_SIDD 89 Best_PSNR_SIDD 17.2613] 
[Ep 18 it 89	 PSNR SIDD: 17.0700	] ----  [best_Ep_SIDD 15 best_it_SIDD 89 Best_PSNR_SIDD 17.2613] 
[Ep 18 it 119	 PSNR SIDD: 17.1862	] ----  [best_Ep_SIDD 15 best_it_SIDD 89 Best_PSNR_SIDD 17.2613] 
Epoch: 18	Time: 26.2222	Loss: 2.7354	LearningRate 0.000194
[Ep 19 it 29	 PSNR SIDD: 16.8670	] ----  [best_Ep_SIDD 15 best_it_SIDD 89 Best_PSNR_SIDD 17.2613] 
[Ep 19 it 59	 PSNR SIDD: 16.5077	] ----  [best_Ep_SIDD 15 best_it_SIDD 89 Best_PSNR_SIDD 17.2613] 
[Ep 19 it 89	 PSNR SIDD: 17.1954	] ----  [best_Ep_SIDD 15 best_it_SIDD 89 Best_PSNR_SIDD 17.2613] 
[Ep 19 it 119	 PSNR SIDD: 17.0295	] ----  [best_Ep_SIDD 15 best_it_SIDD 89 Best_PSNR_SIDD 17.2613] 
Epoch: 19	Time: 26.3159	Loss: 2.6541	LearningRate 0.000194
[Ep 20 it 29	 PSNR SIDD: 17.0960	] ----  [best_Ep_SIDD 15 best_it_SIDD 89 Best_PSNR_SIDD 17.2613] 
[Ep 20 it 59	 PSNR SIDD: 17.0621	] ----  [best_Ep_SIDD 15 best_it_SIDD 89 Best_PSNR_SIDD 17.2613] 
[Ep 20 it 89	 PSNR SIDD: 16.8720	] ----  [best_Ep_SIDD 15 best_it_SIDD 89 Best_PSNR_SIDD 17.2613] 
[Ep 20 it 119	 PSNR SIDD: 16.4906	] ----  [best_Ep_SIDD 15 best_it_SIDD 89 Best_PSNR_SIDD 17.2613] 
Epoch: 20	Time: 25.3978	Loss: 2.6629	LearningRate 0.000193
[Ep 21 it 29	 PSNR SIDD: 16.7519	] ----  [best_Ep_SIDD 15 best_it_SIDD 89 Best_PSNR_SIDD 17.2613] 
[Ep 21 it 59	 PSNR SIDD: 17.2846	] ----  [best_Ep_SIDD 21 best_it_SIDD 59 Best_PSNR_SIDD 17.2846] 
[Ep 21 it 89	 PSNR SIDD: 17.3386	] ----  [best_Ep_SIDD 21 best_it_SIDD 89 Best_PSNR_SIDD 17.3386] 
[Ep 21 it 119	 PSNR SIDD: 16.0158	] ----  [best_Ep_SIDD 21 best_it_SIDD 89 Best_PSNR_SIDD 17.3386] 
Epoch: 21	Time: 26.3052	Loss: 2.3595	LearningRate 0.000192
[Ep 22 it 29	 PSNR SIDD: 17.1934	] ----  [best_Ep_SIDD 21 best_it_SIDD 89 Best_PSNR_SIDD 17.3386] 
[Ep 22 it 59	 PSNR SIDD: 17.3289	] ----  [best_Ep_SIDD 21 best_it_SIDD 89 Best_PSNR_SIDD 17.3386] 
[Ep 22 it 89	 PSNR SIDD: 16.4038	] ----  [best_Ep_SIDD 21 best_it_SIDD 89 Best_PSNR_SIDD 17.3386] 
[Ep 22 it 119	 PSNR SIDD: 17.2779	] ----  [best_Ep_SIDD 21 best_it_SIDD 89 Best_PSNR_SIDD 17.3386] 
Epoch: 22	Time: 24.7029	Loss: 2.3118	LearningRate 0.000191
[Ep 23 it 29	 PSNR SIDD: 17.3485	] ----  [best_Ep_SIDD 23 best_it_SIDD 29 Best_PSNR_SIDD 17.3485] 
[Ep 23 it 59	 PSNR SIDD: 16.3363	] ----  [best_Ep_SIDD 23 best_it_SIDD 29 Best_PSNR_SIDD 17.3485] 
[Ep 23 it 89	 PSNR SIDD: 16.7418	] ----  [best_Ep_SIDD 23 best_it_SIDD 29 Best_PSNR_SIDD 17.3485] 
[Ep 23 it 119	 PSNR SIDD: 16.1923	] ----  [best_Ep_SIDD 23 best_it_SIDD 29 Best_PSNR_SIDD 17.3485] 
Epoch: 23	Time: 25.7861	Loss: 2.4089	LearningRate 0.000190
[Ep 24 it 29	 PSNR SIDD: 17.6311	] ----  [best_Ep_SIDD 24 best_it_SIDD 29 Best_PSNR_SIDD 17.6311] 
[Ep 24 it 59	 PSNR SIDD: 17.5534	] ----  [best_Ep_SIDD 24 best_it_SIDD 29 Best_PSNR_SIDD 17.6311] 
[Ep 24 it 89	 PSNR SIDD: 17.1191	] ----  [best_Ep_SIDD 24 best_it_SIDD 29 Best_PSNR_SIDD 17.6311] 
[Ep 24 it 119	 PSNR SIDD: 18.1650	] ----  [best_Ep_SIDD 24 best_it_SIDD 119 Best_PSNR_SIDD 18.1650] 
Epoch: 24	Time: 27.8898	Loss: 2.1811	LearningRate 0.000189
[Ep 25 it 29	 PSNR SIDD: 17.5852	] ----  [best_Ep_SIDD 24 best_it_SIDD 119 Best_PSNR_SIDD 18.1650] 
[Ep 25 it 59	 PSNR SIDD: 17.7458	] ----  [best_Ep_SIDD 24 best_it_SIDD 119 Best_PSNR_SIDD 18.1650] 
[Ep 25 it 89	 PSNR SIDD: 17.3277	] ----  [best_Ep_SIDD 24 best_it_SIDD 119 Best_PSNR_SIDD 18.1650] 
[Ep 25 it 119	 PSNR SIDD: 17.6813	] ----  [best_Ep_SIDD 24 best_it_SIDD 119 Best_PSNR_SIDD 18.1650] 
Epoch: 25	Time: 26.0289	Loss: 2.1420	LearningRate 0.000188
[Ep 26 it 29	 PSNR SIDD: 17.4248	] ----  [best_Ep_SIDD 24 best_it_SIDD 119 Best_PSNR_SIDD 18.1650] 
[Ep 26 it 59	 PSNR SIDD: 17.4695	] ----  [best_Ep_SIDD 24 best_it_SIDD 119 Best_PSNR_SIDD 18.1650] 
[Ep 26 it 89	 PSNR SIDD: 18.1092	] ----  [best_Ep_SIDD 24 best_it_SIDD 119 Best_PSNR_SIDD 18.1650] 
[Ep 26 it 119	 PSNR SIDD: 17.7870	] ----  [best_Ep_SIDD 24 best_it_SIDD 119 Best_PSNR_SIDD 18.1650] 
Epoch: 26	Time: 24.8201	Loss: 2.1367	LearningRate 0.000187
[Ep 27 it 29	 PSNR SIDD: 17.9578	] ----  [best_Ep_SIDD 24 best_it_SIDD 119 Best_PSNR_SIDD 18.1650] 
[Ep 27 it 59	 PSNR SIDD: 18.3011	] ----  [best_Ep_SIDD 27 best_it_SIDD 59 Best_PSNR_SIDD 18.3011] 
[Ep 27 it 89	 PSNR SIDD: 18.3213	] ----  [best_Ep_SIDD 27 best_it_SIDD 89 Best_PSNR_SIDD 18.3213] 
[Ep 27 it 119	 PSNR SIDD: 17.5498	] ----  [best_Ep_SIDD 27 best_it_SIDD 89 Best_PSNR_SIDD 18.3213] 
Epoch: 27	Time: 26.3626	Loss: 2.0364	LearningRate 0.000186
[Ep 28 it 29	 PSNR SIDD: 17.5343	] ----  [best_Ep_SIDD 27 best_it_SIDD 89 Best_PSNR_SIDD 18.3213] 
[Ep 28 it 59	 PSNR SIDD: 17.4575	] ----  [best_Ep_SIDD 27 best_it_SIDD 89 Best_PSNR_SIDD 18.3213] 
[Ep 28 it 89	 PSNR SIDD: 17.9909	] ----  [best_Ep_SIDD 27 best_it_SIDD 89 Best_PSNR_SIDD 18.3213] 
[Ep 28 it 119	 PSNR SIDD: 18.0744	] ----  [best_Ep_SIDD 27 best_it_SIDD 89 Best_PSNR_SIDD 18.3213] 
Epoch: 28	Time: 26.2198	Loss: 2.0251	LearningRate 0.000185
[Ep 29 it 29	 PSNR SIDD: 17.0223	] ----  [best_Ep_SIDD 27 best_it_SIDD 89 Best_PSNR_SIDD 18.3213] 
[Ep 29 it 59	 PSNR SIDD: 17.7421	] ----  [best_Ep_SIDD 27 best_it_SIDD 89 Best_PSNR_SIDD 18.3213] 
[Ep 29 it 89	 PSNR SIDD: 17.8234	] ----  [best_Ep_SIDD 27 best_it_SIDD 89 Best_PSNR_SIDD 18.3213] 
[Ep 29 it 119	 PSNR SIDD: 17.7003	] ----  [best_Ep_SIDD 27 best_it_SIDD 89 Best_PSNR_SIDD 18.3213] 
Epoch: 29	Time: 25.7995	Loss: 2.2137	LearningRate 0.000184
[Ep 30 it 29	 PSNR SIDD: 17.4745	] ----  [best_Ep_SIDD 27 best_it_SIDD 89 Best_PSNR_SIDD 18.3213] 
[Ep 30 it 59	 PSNR SIDD: 17.8782	] ----  [best_Ep_SIDD 27 best_it_SIDD 89 Best_PSNR_SIDD 18.3213] 
[Ep 30 it 89	 PSNR SIDD: 18.4805	] ----  [best_Ep_SIDD 30 best_it_SIDD 89 Best_PSNR_SIDD 18.4805] 
[Ep 30 it 119	 PSNR SIDD: 18.0526	] ----  [best_Ep_SIDD 30 best_it_SIDD 89 Best_PSNR_SIDD 18.4805] 
Epoch: 30	Time: 26.7337	Loss: 2.0791	LearningRate 0.000183
[Ep 31 it 29	 PSNR SIDD: 17.8964	] ----  [best_Ep_SIDD 30 best_it_SIDD 89 Best_PSNR_SIDD 18.4805] 
[Ep 31 it 59	 PSNR SIDD: 17.4744	] ----  [best_Ep_SIDD 30 best_it_SIDD 89 Best_PSNR_SIDD 18.4805] 
[Ep 31 it 89	 PSNR SIDD: 18.0096	] ----  [best_Ep_SIDD 30 best_it_SIDD 89 Best_PSNR_SIDD 18.4805] 
[Ep 31 it 119	 PSNR SIDD: 17.8468	] ----  [best_Ep_SIDD 30 best_it_SIDD 89 Best_PSNR_SIDD 18.4805] 
Epoch: 31	Time: 25.3268	Loss: 1.9906	LearningRate 0.000182
[Ep 32 it 29	 PSNR SIDD: 17.5350	] ----  [best_Ep_SIDD 30 best_it_SIDD 89 Best_PSNR_SIDD 18.4805] 
[Ep 32 it 59	 PSNR SIDD: 17.7607	] ----  [best_Ep_SIDD 30 best_it_SIDD 89 Best_PSNR_SIDD 18.4805] 
[Ep 32 it 89	 PSNR SIDD: 17.7383	] ----  [best_Ep_SIDD 30 best_it_SIDD 89 Best_PSNR_SIDD 18.4805] 
[Ep 32 it 119	 PSNR SIDD: 17.6092	] ----  [best_Ep_SIDD 30 best_it_SIDD 89 Best_PSNR_SIDD 18.4805] 
Epoch: 32	Time: 24.8897	Loss: 2.0169	LearningRate 0.000180
[Ep 33 it 29	 PSNR SIDD: 18.3315	] ----  [best_Ep_SIDD 30 best_it_SIDD 89 Best_PSNR_SIDD 18.4805] 
[Ep 33 it 59	 PSNR SIDD: 18.3300	] ----  [best_Ep_SIDD 30 best_it_SIDD 89 Best_PSNR_SIDD 18.4805] 
[Ep 33 it 89	 PSNR SIDD: 18.2027	] ----  [best_Ep_SIDD 30 best_it_SIDD 89 Best_PSNR_SIDD 18.4805] 
[Ep 33 it 119	 PSNR SIDD: 18.5594	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
Epoch: 33	Time: 26.1559	Loss: 2.0964	LearningRate 0.000179
[Ep 34 it 29	 PSNR SIDD: 18.0394	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
[Ep 34 it 59	 PSNR SIDD: 17.3769	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
[Ep 34 it 89	 PSNR SIDD: 18.0637	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
[Ep 34 it 119	 PSNR SIDD: 17.9620	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
Epoch: 34	Time: 25.0306	Loss: 1.9673	LearningRate 0.000178
[Ep 35 it 29	 PSNR SIDD: 18.3570	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
[Ep 35 it 59	 PSNR SIDD: 17.5545	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
[Ep 35 it 89	 PSNR SIDD: 18.3415	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
[Ep 35 it 119	 PSNR SIDD: 18.3681	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
Epoch: 35	Time: 26.5441	Loss: 1.9695	LearningRate 0.000176
[Ep 36 it 29	 PSNR SIDD: 18.0373	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
[Ep 36 it 59	 PSNR SIDD: 17.9930	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
[Ep 36 it 89	 PSNR SIDD: 18.2133	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
[Ep 36 it 119	 PSNR SIDD: 17.4062	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
Epoch: 36	Time: 25.0862	Loss: 1.8908	LearningRate 0.000175
[Ep 37 it 29	 PSNR SIDD: 18.0586	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
[Ep 37 it 59	 PSNR SIDD: 18.3548	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
[Ep 37 it 89	 PSNR SIDD: 17.6936	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
[Ep 37 it 119	 PSNR SIDD: 18.2409	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
Epoch: 37	Time: 25.3668	Loss: 1.8690	LearningRate 0.000173
[Ep 38 it 29	 PSNR SIDD: 18.1686	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
[Ep 38 it 59	 PSNR SIDD: 17.9773	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
[Ep 38 it 89	 PSNR SIDD: 18.1495	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
[Ep 38 it 119	 PSNR SIDD: 17.9899	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
Epoch: 38	Time: 25.3781	Loss: 1.9476	LearningRate 0.000172
[Ep 39 it 29	 PSNR SIDD: 17.9377	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
[Ep 39 it 59	 PSNR SIDD: 17.9748	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
[Ep 39 it 89	 PSNR SIDD: 17.0946	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
[Ep 39 it 119	 PSNR SIDD: 17.5675	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
Epoch: 39	Time: 24.4183	Loss: 1.9308	LearningRate 0.000171
[Ep 40 it 29	 PSNR SIDD: 17.9037	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
[Ep 40 it 59	 PSNR SIDD: 18.3854	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
[Ep 40 it 89	 PSNR SIDD: 17.6959	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
[Ep 40 it 119	 PSNR SIDD: 17.8107	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
Epoch: 40	Time: 24.8671	Loss: 1.8341	LearningRate 0.000169
[Ep 41 it 29	 PSNR SIDD: 16.9715	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
[Ep 41 it 59	 PSNR SIDD: 18.5143	] ----  [best_Ep_SIDD 33 best_it_SIDD 119 Best_PSNR_SIDD 18.5594] 
[Ep 41 it 89	 PSNR SIDD: 18.6288	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
[Ep 41 it 119	 PSNR SIDD: 17.8985	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
Epoch: 41	Time: 26.5878	Loss: 1.8925	LearningRate 0.000167
[Ep 42 it 29	 PSNR SIDD: 17.5604	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
[Ep 42 it 59	 PSNR SIDD: 18.1515	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
[Ep 42 it 89	 PSNR SIDD: 18.5587	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
[Ep 42 it 119	 PSNR SIDD: 17.9627	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
Epoch: 42	Time: 26.2919	Loss: 1.9272	LearningRate 0.000166
[Ep 43 it 29	 PSNR SIDD: 18.4484	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
[Ep 43 it 59	 PSNR SIDD: 18.4584	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
[Ep 43 it 89	 PSNR SIDD: 17.5832	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
[Ep 43 it 119	 PSNR SIDD: 18.2863	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
Epoch: 43	Time: 26.3393	Loss: 1.9995	LearningRate 0.000164
[Ep 44 it 29	 PSNR SIDD: 18.3182	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
[Ep 44 it 59	 PSNR SIDD: 18.1044	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
[Ep 44 it 89	 PSNR SIDD: 18.2662	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
[Ep 44 it 119	 PSNR SIDD: 18.6007	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
Epoch: 44	Time: 25.7979	Loss: 1.9164	LearningRate 0.000163
[Ep 45 it 29	 PSNR SIDD: 18.4669	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
[Ep 45 it 59	 PSNR SIDD: 18.4227	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
[Ep 45 it 89	 PSNR SIDD: 18.0328	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
[Ep 45 it 119	 PSNR SIDD: 17.5842	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
Epoch: 45	Time: 26.1616	Loss: 1.8933	LearningRate 0.000161
[Ep 46 it 29	 PSNR SIDD: 17.7151	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
[Ep 46 it 59	 PSNR SIDD: 17.9592	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
[Ep 46 it 89	 PSNR SIDD: 18.2723	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
[Ep 46 it 119	 PSNR SIDD: 17.7646	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
Epoch: 46	Time: 25.7304	Loss: 1.9344	LearningRate 0.000159
[Ep 47 it 29	 PSNR SIDD: 18.5912	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
[Ep 47 it 59	 PSNR SIDD: 18.5093	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
[Ep 47 it 89	 PSNR SIDD: 17.3976	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
[Ep 47 it 119	 PSNR SIDD: 18.5871	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
Epoch: 47	Time: 25.6959	Loss: 1.9602	LearningRate 0.000157
[Ep 48 it 29	 PSNR SIDD: 18.3879	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
[Ep 48 it 59	 PSNR SIDD: 18.5203	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
[Ep 48 it 89	 PSNR SIDD: 18.3882	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
[Ep 48 it 119	 PSNR SIDD: 18.2544	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
Epoch: 48	Time: 24.7723	Loss: 1.8320	LearningRate 0.000156
[Ep 49 it 29	 PSNR SIDD: 18.0066	] ----  [best_Ep_SIDD 41 best_it_SIDD 89 Best_PSNR_SIDD 18.6288] 
[Ep 49 it 59	 PSNR SIDD: 18.7445	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 18.7445] 
[Ep 49 it 89	 PSNR SIDD: 17.8532	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 18.7445] 
[Ep 49 it 119	 PSNR SIDD: 17.8306	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 18.7445] 
Epoch: 49	Time: 25.0869	Loss: 1.8395	LearningRate 0.000154
[Ep 50 it 29	 PSNR SIDD: 18.4185	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 18.7445] 
[Ep 50 it 59	 PSNR SIDD: 18.1812	] ----  [best_Ep_SIDD 49 best_it_SIDD 59 Best_PSNR_SIDD 18.7445] 
[Ep 50 it 89	 PSNR SIDD: 18.7604	] ----  [best_Ep_SIDD 50 best_it_SIDD 89 Best_PSNR_SIDD 18.7604] 
[Ep 50 it 119	 PSNR SIDD: 18.7155	] ----  [best_Ep_SIDD 50 best_it_SIDD 89 Best_PSNR_SIDD 18.7604] 
Epoch: 50	Time: 25.8034	Loss: 1.8251	LearningRate 0.000152
[Ep 51 it 29	 PSNR SIDD: 18.1473	] ----  [best_Ep_SIDD 50 best_it_SIDD 89 Best_PSNR_SIDD 18.7604] 
[Ep 51 it 59	 PSNR SIDD: 18.6062	] ----  [best_Ep_SIDD 50 best_it_SIDD 89 Best_PSNR_SIDD 18.7604] 
[Ep 51 it 89	 PSNR SIDD: 18.3438	] ----  [best_Ep_SIDD 50 best_it_SIDD 89 Best_PSNR_SIDD 18.7604] 
[Ep 51 it 119	 PSNR SIDD: 17.9789	] ----  [best_Ep_SIDD 50 best_it_SIDD 89 Best_PSNR_SIDD 18.7604] 
Epoch: 51	Time: 25.4054	Loss: 1.8968	LearningRate 0.000150
[Ep 52 it 29	 PSNR SIDD: 18.3482	] ----  [best_Ep_SIDD 50 best_it_SIDD 89 Best_PSNR_SIDD 18.7604] 
[Ep 52 it 59	 PSNR SIDD: 17.9291	] ----  [best_Ep_SIDD 50 best_it_SIDD 89 Best_PSNR_SIDD 18.7604] 
[Ep 52 it 89	 PSNR SIDD: 17.7643	] ----  [best_Ep_SIDD 50 best_it_SIDD 89 Best_PSNR_SIDD 18.7604] 
[Ep 52 it 119	 PSNR SIDD: 17.8595	] ----  [best_Ep_SIDD 50 best_it_SIDD 89 Best_PSNR_SIDD 18.7604] 
Epoch: 52	Time: 24.9764	Loss: 1.8430	LearningRate 0.000148
[Ep 53 it 29	 PSNR SIDD: 18.2826	] ----  [best_Ep_SIDD 50 best_it_SIDD 89 Best_PSNR_SIDD 18.7604] 
[Ep 53 it 59	 PSNR SIDD: 18.5965	] ----  [best_Ep_SIDD 50 best_it_SIDD 89 Best_PSNR_SIDD 18.7604] 
[Ep 53 it 89	 PSNR SIDD: 17.7196	] ----  [best_Ep_SIDD 50 best_it_SIDD 89 Best_PSNR_SIDD 18.7604] 
[Ep 53 it 119	 PSNR SIDD: 18.1632	] ----  [best_Ep_SIDD 50 best_it_SIDD 89 Best_PSNR_SIDD 18.7604] 
Epoch: 53	Time: 24.0328	Loss: 1.8374	LearningRate 0.000147
[Ep 54 it 29	 PSNR SIDD: 18.1026	] ----  [best_Ep_SIDD 50 best_it_SIDD 89 Best_PSNR_SIDD 18.7604] 
[Ep 54 it 59	 PSNR SIDD: 18.5620	] ----  [best_Ep_SIDD 50 best_it_SIDD 89 Best_PSNR_SIDD 18.7604] 
[Ep 54 it 89	 PSNR SIDD: 18.4430	] ----  [best_Ep_SIDD 50 best_it_SIDD 89 Best_PSNR_SIDD 18.7604] 
[Ep 54 it 119	 PSNR SIDD: 18.5014	] ----  [best_Ep_SIDD 50 best_it_SIDD 89 Best_PSNR_SIDD 18.7604] 
Epoch: 54	Time: 24.6886	Loss: 1.8725	LearningRate 0.000145
[Ep 55 it 29	 PSNR SIDD: 18.4580	] ----  [best_Ep_SIDD 50 best_it_SIDD 89 Best_PSNR_SIDD 18.7604] 
[Ep 55 it 59	 PSNR SIDD: 18.8278	] ----  [best_Ep_SIDD 55 best_it_SIDD 59 Best_PSNR_SIDD 18.8278] 
[Ep 55 it 89	 PSNR SIDD: 18.6830	] ----  [best_Ep_SIDD 55 best_it_SIDD 59 Best_PSNR_SIDD 18.8278] 
[Ep 55 it 119	 PSNR SIDD: 18.4711	] ----  [best_Ep_SIDD 55 best_it_SIDD 59 Best_PSNR_SIDD 18.8278] 
Epoch: 55	Time: 25.8604	Loss: 1.8457	LearningRate 0.000143
[Ep 56 it 29	 PSNR SIDD: 18.1272	] ----  [best_Ep_SIDD 55 best_it_SIDD 59 Best_PSNR_SIDD 18.8278] 
[Ep 56 it 59	 PSNR SIDD: 18.2828	] ----  [best_Ep_SIDD 55 best_it_SIDD 59 Best_PSNR_SIDD 18.8278] 
[Ep 56 it 89	 PSNR SIDD: 18.1527	] ----  [best_Ep_SIDD 55 best_it_SIDD 59 Best_PSNR_SIDD 18.8278] 
[Ep 56 it 119	 PSNR SIDD: 18.1712	] ----  [best_Ep_SIDD 55 best_it_SIDD 59 Best_PSNR_SIDD 18.8278] 
Epoch: 56	Time: 25.6253	Loss: 1.8217	LearningRate 0.000141
[Ep 57 it 29	 PSNR SIDD: 18.3552	] ----  [best_Ep_SIDD 55 best_it_SIDD 59 Best_PSNR_SIDD 18.8278] 
[Ep 57 it 59	 PSNR SIDD: 18.9250	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 57 it 89	 PSNR SIDD: 18.2023	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 57 it 119	 PSNR SIDD: 18.2510	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
Epoch: 57	Time: 24.8506	Loss: 1.7442	LearningRate 0.000139
[Ep 58 it 29	 PSNR SIDD: 18.4789	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 58 it 59	 PSNR SIDD: 18.1300	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 58 it 89	 PSNR SIDD: 18.2451	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 58 it 119	 PSNR SIDD: 18.7883	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
Epoch: 58	Time: 24.8596	Loss: 1.7638	LearningRate 0.000137
[Ep 59 it 29	 PSNR SIDD: 18.4673	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 59 it 59	 PSNR SIDD: 18.6151	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 59 it 89	 PSNR SIDD: 18.1437	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 59 it 119	 PSNR SIDD: 18.3219	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
Epoch: 59	Time: 26.4950	Loss: 1.7537	LearningRate 0.000135
[Ep 60 it 29	 PSNR SIDD: 18.3935	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 60 it 59	 PSNR SIDD: 18.1945	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 60 it 89	 PSNR SIDD: 18.2790	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 60 it 119	 PSNR SIDD: 18.6602	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
Epoch: 60	Time: 25.6395	Loss: 1.7451	LearningRate 0.000133
[Ep 61 it 29	 PSNR SIDD: 18.6440	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 61 it 59	 PSNR SIDD: 18.3418	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 61 it 89	 PSNR SIDD: 18.3447	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 61 it 119	 PSNR SIDD: 18.8010	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
Epoch: 61	Time: 26.0300	Loss: 1.6533	LearningRate 0.000131
[Ep 62 it 29	 PSNR SIDD: 18.5829	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 62 it 59	 PSNR SIDD: 18.9135	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 62 it 89	 PSNR SIDD: 18.4419	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 62 it 119	 PSNR SIDD: 18.7435	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
Epoch: 62	Time: 25.4434	Loss: 1.7582	LearningRate 0.000129
[Ep 63 it 29	 PSNR SIDD: 18.6477	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 63 it 59	 PSNR SIDD: 18.6141	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 63 it 89	 PSNR SIDD: 18.3148	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 63 it 119	 PSNR SIDD: 18.6038	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
Epoch: 63	Time: 25.5685	Loss: 1.7425	LearningRate 0.000127
[Ep 64 it 29	 PSNR SIDD: 18.6985	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 64 it 59	 PSNR SIDD: 18.7049	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 64 it 89	 PSNR SIDD: 18.6686	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 64 it 119	 PSNR SIDD: 18.2001	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
Epoch: 64	Time: 25.7898	Loss: 1.7234	LearningRate 0.000125
[Ep 65 it 29	 PSNR SIDD: 18.4703	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 65 it 59	 PSNR SIDD: 18.8014	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 65 it 89	 PSNR SIDD: 18.3699	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 65 it 119	 PSNR SIDD: 18.1923	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
Epoch: 65	Time: 26.8796	Loss: 1.6712	LearningRate 0.000123
[Ep 66 it 29	 PSNR SIDD: 18.6037	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 66 it 59	 PSNR SIDD: 17.9387	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 66 it 89	 PSNR SIDD: 18.6131	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 66 it 119	 PSNR SIDD: 18.9030	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
Epoch: 66	Time: 25.1654	Loss: 1.6651	LearningRate 0.000121
[Ep 67 it 29	 PSNR SIDD: 18.6320	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 67 it 59	 PSNR SIDD: 18.5907	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 67 it 89	 PSNR SIDD: 18.4697	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 67 it 119	 PSNR SIDD: 18.4194	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
Epoch: 67	Time: 24.9840	Loss: 1.7472	LearningRate 0.000119
[Ep 68 it 29	 PSNR SIDD: 18.6764	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 68 it 59	 PSNR SIDD: 18.7357	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 68 it 89	 PSNR SIDD: 18.5718	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 68 it 119	 PSNR SIDD: 18.5495	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
Epoch: 68	Time: 25.5619	Loss: 1.7955	LearningRate 0.000116
[Ep 69 it 29	 PSNR SIDD: 18.5986	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 69 it 59	 PSNR SIDD: 18.3302	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 69 it 89	 PSNR SIDD: 18.6970	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 69 it 119	 PSNR SIDD: 18.6784	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
Epoch: 69	Time: 25.5143	Loss: 1.6547	LearningRate 0.000114
[Ep 70 it 29	 PSNR SIDD: 18.4217	] ----  [best_Ep_SIDD 57 best_it_SIDD 59 Best_PSNR_SIDD 18.9250] 
[Ep 70 it 59	 PSNR SIDD: 18.9509	] ----  [best_Ep_SIDD 70 best_it_SIDD 59 Best_PSNR_SIDD 18.9509] 
[Ep 70 it 89	 PSNR SIDD: 18.6592	] ----  [best_Ep_SIDD 70 best_it_SIDD 59 Best_PSNR_SIDD 18.9509] 
[Ep 70 it 119	 PSNR SIDD: 18.8931	] ----  [best_Ep_SIDD 70 best_it_SIDD 59 Best_PSNR_SIDD 18.9509] 
Epoch: 70	Time: 24.5059	Loss: 1.6721	LearningRate 0.000112
[Ep 71 it 29	 PSNR SIDD: 18.7274	] ----  [best_Ep_SIDD 70 best_it_SIDD 59 Best_PSNR_SIDD 18.9509] 
[Ep 71 it 59	 PSNR SIDD: 18.5843	] ----  [best_Ep_SIDD 70 best_it_SIDD 59 Best_PSNR_SIDD 18.9509] 
[Ep 71 it 89	 PSNR SIDD: 18.2844	] ----  [best_Ep_SIDD 70 best_it_SIDD 59 Best_PSNR_SIDD 18.9509] 
[Ep 71 it 119	 PSNR SIDD: 18.3420	] ----  [best_Ep_SIDD 70 best_it_SIDD 59 Best_PSNR_SIDD 18.9509] 
Epoch: 71	Time: 25.7890	Loss: 1.6679	LearningRate 0.000110
[Ep 72 it 29	 PSNR SIDD: 18.9293	] ----  [best_Ep_SIDD 70 best_it_SIDD 59 Best_PSNR_SIDD 18.9509] 
[Ep 72 it 59	 PSNR SIDD: 18.8555	] ----  [best_Ep_SIDD 70 best_it_SIDD 59 Best_PSNR_SIDD 18.9509] 
[Ep 72 it 89	 PSNR SIDD: 18.6699	] ----  [best_Ep_SIDD 70 best_it_SIDD 59 Best_PSNR_SIDD 18.9509] 
[Ep 72 it 119	 PSNR SIDD: 18.8410	] ----  [best_Ep_SIDD 70 best_it_SIDD 59 Best_PSNR_SIDD 18.9509] 
Epoch: 72	Time: 26.8542	Loss: 1.6596	LearningRate 0.000108
[Ep 73 it 29	 PSNR SIDD: 18.8621	] ----  [best_Ep_SIDD 70 best_it_SIDD 59 Best_PSNR_SIDD 18.9509] 
[Ep 73 it 59	 PSNR SIDD: 18.1911	] ----  [best_Ep_SIDD 70 best_it_SIDD 59 Best_PSNR_SIDD 18.9509] 
[Ep 73 it 89	 PSNR SIDD: 18.3689	] ----  [best_Ep_SIDD 70 best_it_SIDD 59 Best_PSNR_SIDD 18.9509] 
[Ep 73 it 119	 PSNR SIDD: 18.2723	] ----  [best_Ep_SIDD 70 best_it_SIDD 59 Best_PSNR_SIDD 18.9509] 
Epoch: 73	Time: 27.1252	Loss: 1.6565	LearningRate 0.000106
[Ep 74 it 29	 PSNR SIDD: 18.8392	] ----  [best_Ep_SIDD 70 best_it_SIDD 59 Best_PSNR_SIDD 18.9509] 
[Ep 74 it 59	 PSNR SIDD: 18.2444	] ----  [best_Ep_SIDD 70 best_it_SIDD 59 Best_PSNR_SIDD 18.9509] 
[Ep 74 it 89	 PSNR SIDD: 18.3918	] ----  [best_Ep_SIDD 70 best_it_SIDD 59 Best_PSNR_SIDD 18.9509] 
[Ep 74 it 119	 PSNR SIDD: 19.0646	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
Epoch: 74	Time: 25.1303	Loss: 1.6451	LearningRate 0.000104
[Ep 75 it 29	 PSNR SIDD: 18.7746	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 75 it 59	 PSNR SIDD: 18.8451	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 75 it 89	 PSNR SIDD: 18.5813	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 75 it 119	 PSNR SIDD: 18.6659	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
Epoch: 75	Time: 25.6095	Loss: 1.6787	LearningRate 0.000102
[Ep 76 it 29	 PSNR SIDD: 18.5587	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 76 it 59	 PSNR SIDD: 18.2964	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 76 it 89	 PSNR SIDD: 18.8871	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 76 it 119	 PSNR SIDD: 18.9478	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
Epoch: 76	Time: 26.7923	Loss: 1.6912	LearningRate 0.000099
[Ep 77 it 29	 PSNR SIDD: 18.4525	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 77 it 59	 PSNR SIDD: 18.9636	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 77 it 89	 PSNR SIDD: 18.3077	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 77 it 119	 PSNR SIDD: 18.2347	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
Epoch: 77	Time: 25.9017	Loss: 1.6759	LearningRate 0.000097
[Ep 78 it 29	 PSNR SIDD: 18.6354	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 78 it 59	 PSNR SIDD: 18.7867	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 78 it 89	 PSNR SIDD: 18.7512	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 78 it 119	 PSNR SIDD: 18.6426	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
Epoch: 78	Time: 25.8281	Loss: 1.5912	LearningRate 0.000095
[Ep 79 it 29	 PSNR SIDD: 18.8157	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 79 it 59	 PSNR SIDD: 18.3815	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 79 it 89	 PSNR SIDD: 18.4014	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 79 it 119	 PSNR SIDD: 18.8377	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
Epoch: 79	Time: 24.9672	Loss: 1.5813	LearningRate 0.000093
[Ep 80 it 29	 PSNR SIDD: 18.5509	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 80 it 59	 PSNR SIDD: 18.5165	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 80 it 89	 PSNR SIDD: 18.8744	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 80 it 119	 PSNR SIDD: 18.8905	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
Epoch: 80	Time: 25.3738	Loss: 1.6762	LearningRate 0.000091
[Ep 81 it 29	 PSNR SIDD: 18.8573	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 81 it 59	 PSNR SIDD: 18.8830	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 81 it 89	 PSNR SIDD: 18.8697	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 81 it 119	 PSNR SIDD: 18.8751	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
Epoch: 81	Time: 25.7321	Loss: 1.5611	LearningRate 0.000089
[Ep 82 it 29	 PSNR SIDD: 18.8590	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 82 it 59	 PSNR SIDD: 18.3269	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 82 it 89	 PSNR SIDD: 18.4766	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 82 it 119	 PSNR SIDD: 18.8546	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
Epoch: 82	Time: 25.6172	Loss: 1.6193	LearningRate 0.000087
[Ep 83 it 29	 PSNR SIDD: 18.8995	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 83 it 59	 PSNR SIDD: 18.4420	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 83 it 89	 PSNR SIDD: 18.8487	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 83 it 119	 PSNR SIDD: 18.4977	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
Epoch: 83	Time: 25.0927	Loss: 1.5961	LearningRate 0.000085
[Ep 84 it 29	 PSNR SIDD: 18.6674	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 84 it 59	 PSNR SIDD: 18.5778	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 84 it 89	 PSNR SIDD: 18.6000	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 84 it 119	 PSNR SIDD: 18.6200	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
Epoch: 84	Time: 25.5710	Loss: 1.6305	LearningRate 0.000083
[Ep 85 it 29	 PSNR SIDD: 18.4599	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 85 it 59	 PSNR SIDD: 18.9468	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 85 it 89	 PSNR SIDD: 18.8695	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 85 it 119	 PSNR SIDD: 18.7822	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
Epoch: 85	Time: 25.6026	Loss: 1.6203	LearningRate 0.000080
[Ep 86 it 29	 PSNR SIDD: 19.0266	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 86 it 59	 PSNR SIDD: 18.4357	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 86 it 89	 PSNR SIDD: 18.3922	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 86 it 119	 PSNR SIDD: 18.6257	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
Epoch: 86	Time: 25.1393	Loss: 1.5841	LearningRate 0.000078
[Ep 87 it 29	 PSNR SIDD: 18.7487	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 87 it 59	 PSNR SIDD: 18.5436	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 87 it 89	 PSNR SIDD: 18.7444	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 87 it 119	 PSNR SIDD: 18.6502	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
Epoch: 87	Time: 25.0149	Loss: 1.5552	LearningRate 0.000076
[Ep 88 it 29	 PSNR SIDD: 18.5645	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 88 it 59	 PSNR SIDD: 18.4701	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 88 it 89	 PSNR SIDD: 18.5575	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 88 it 119	 PSNR SIDD: 18.5167	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
Epoch: 88	Time: 26.3784	Loss: 1.6034	LearningRate 0.000074
[Ep 89 it 29	 PSNR SIDD: 18.4384	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 89 it 59	 PSNR SIDD: 18.8156	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 89 it 89	 PSNR SIDD: 18.8975	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 89 it 119	 PSNR SIDD: 18.6805	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
Epoch: 89	Time: 25.3882	Loss: 1.5740	LearningRate 0.000072
[Ep 90 it 29	 PSNR SIDD: 18.5995	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 90 it 59	 PSNR SIDD: 19.0235	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 90 it 89	 PSNR SIDD: 18.7316	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 90 it 119	 PSNR SIDD: 18.7479	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
Epoch: 90	Time: 24.6401	Loss: 1.6004	LearningRate 0.000070
[Ep 91 it 29	 PSNR SIDD: 18.9399	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 91 it 59	 PSNR SIDD: 18.6399	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 91 it 89	 PSNR SIDD: 18.4808	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 91 it 119	 PSNR SIDD: 18.5235	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
Epoch: 91	Time: 26.1582	Loss: 1.5152	LearningRate 0.000068
[Ep 92 it 29	 PSNR SIDD: 18.8504	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 92 it 59	 PSNR SIDD: 18.5010	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 92 it 89	 PSNR SIDD: 18.5610	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 92 it 119	 PSNR SIDD: 18.6824	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
Epoch: 92	Time: 25.6032	Loss: 1.5508	LearningRate 0.000066
[Ep 93 it 29	 PSNR SIDD: 18.6032	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 93 it 59	 PSNR SIDD: 18.7790	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 93 it 89	 PSNR SIDD: 18.6326	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
[Ep 93 it 119	 PSNR SIDD: 18.9765	] ----  [best_Ep_SIDD 74 best_it_SIDD 119 Best_PSNR_SIDD 19.0646] 
Epoch: 93	Time: 25.3860	Loss: 1.5867	LearningRate 0.000064
[Ep 94 it 29	 PSNR SIDD: 19.0772	] ----  [best_Ep_SIDD 94 best_it_SIDD 29 Best_PSNR_SIDD 19.0772] 
[Ep 94 it 59	 PSNR SIDD: 18.6921	] ----  [best_Ep_SIDD 94 best_it_SIDD 29 Best_PSNR_SIDD 19.0772] 
[Ep 94 it 89	 PSNR SIDD: 18.1492	] ----  [best_Ep_SIDD 94 best_it_SIDD 29 Best_PSNR_SIDD 19.0772] 
[Ep 94 it 119	 PSNR SIDD: 18.7398	] ----  [best_Ep_SIDD 94 best_it_SIDD 29 Best_PSNR_SIDD 19.0772] 
Epoch: 94	Time: 26.5793	Loss: 1.5650	LearningRate 0.000062
[Ep 95 it 29	 PSNR SIDD: 18.7091	] ----  [best_Ep_SIDD 94 best_it_SIDD 29 Best_PSNR_SIDD 19.0772] 
[Ep 95 it 59	 PSNR SIDD: 18.7400	] ----  [best_Ep_SIDD 94 best_it_SIDD 29 Best_PSNR_SIDD 19.0772] 
[Ep 95 it 89	 PSNR SIDD: 18.9224	] ----  [best_Ep_SIDD 94 best_it_SIDD 29 Best_PSNR_SIDD 19.0772] 
[Ep 95 it 119	 PSNR SIDD: 19.1867	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
Epoch: 95	Time: 25.9632	Loss: 1.5075	LearningRate 0.000060
[Ep 96 it 29	 PSNR SIDD: 18.9313	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 96 it 59	 PSNR SIDD: 19.1458	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 96 it 89	 PSNR SIDD: 18.7538	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 96 it 119	 PSNR SIDD: 19.1268	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
Epoch: 96	Time: 25.3334	Loss: 1.4998	LearningRate 0.000058
[Ep 97 it 29	 PSNR SIDD: 18.9735	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 97 it 59	 PSNR SIDD: 18.9969	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 97 it 89	 PSNR SIDD: 18.7457	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 97 it 119	 PSNR SIDD: 18.7219	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
Epoch: 97	Time: 25.6694	Loss: 1.5410	LearningRate 0.000056
[Ep 98 it 29	 PSNR SIDD: 18.6157	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 98 it 59	 PSNR SIDD: 18.5597	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 98 it 89	 PSNR SIDD: 19.0219	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 98 it 119	 PSNR SIDD: 18.9680	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
Epoch: 98	Time: 25.5251	Loss: 1.5377	LearningRate 0.000055
[Ep 99 it 29	 PSNR SIDD: 18.7474	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 99 it 59	 PSNR SIDD: 19.0256	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 99 it 89	 PSNR SIDD: 18.6666	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 99 it 119	 PSNR SIDD: 18.6026	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
Epoch: 99	Time: 26.2100	Loss: 1.5702	LearningRate 0.000053
[Ep 100 it 29	 PSNR SIDD: 19.0033	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 100 it 59	 PSNR SIDD: 18.5041	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 100 it 89	 PSNR SIDD: 18.7962	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 100 it 119	 PSNR SIDD: 18.9110	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
Epoch: 100	Time: 25.7379	Loss: 1.4692	LearningRate 0.000051
[Ep 101 it 29	 PSNR SIDD: 18.6576	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 101 it 59	 PSNR SIDD: 18.7651	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 101 it 89	 PSNR SIDD: 18.6758	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 101 it 119	 PSNR SIDD: 18.8898	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
Epoch: 101	Time: 26.1556	Loss: 1.5259	LearningRate 0.000049
[Ep 102 it 29	 PSNR SIDD: 18.5764	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 102 it 59	 PSNR SIDD: 18.7597	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 102 it 89	 PSNR SIDD: 19.0463	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 102 it 119	 PSNR SIDD: 18.7776	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
Epoch: 102	Time: 26.2175	Loss: 1.5438	LearningRate 0.000047
[Ep 103 it 29	 PSNR SIDD: 18.6546	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 103 it 59	 PSNR SIDD: 18.6428	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 103 it 89	 PSNR SIDD: 18.8634	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 103 it 119	 PSNR SIDD: 18.9898	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
Epoch: 103	Time: 25.8698	Loss: 1.5334	LearningRate 0.000045
[Ep 104 it 29	 PSNR SIDD: 19.0785	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 104 it 59	 PSNR SIDD: 18.6352	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 104 it 89	 PSNR SIDD: 19.0484	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 104 it 119	 PSNR SIDD: 18.7063	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
Epoch: 104	Time: 25.7673	Loss: 1.5705	LearningRate 0.000044
[Ep 105 it 29	 PSNR SIDD: 18.9107	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 105 it 59	 PSNR SIDD: 19.0241	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 105 it 89	 PSNR SIDD: 18.5706	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 105 it 119	 PSNR SIDD: 19.0855	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
Epoch: 105	Time: 26.8014	Loss: 1.5396	LearningRate 0.000042
[Ep 106 it 29	 PSNR SIDD: 18.8893	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 106 it 59	 PSNR SIDD: 18.6872	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 106 it 89	 PSNR SIDD: 18.7703	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 106 it 119	 PSNR SIDD: 19.0357	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
Epoch: 106	Time: 26.3113	Loss: 1.5125	LearningRate 0.000040
[Ep 107 it 29	 PSNR SIDD: 18.8394	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 107 it 59	 PSNR SIDD: 18.8066	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 107 it 89	 PSNR SIDD: 18.8574	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 107 it 119	 PSNR SIDD: 18.7587	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
Epoch: 107	Time: 25.7927	Loss: 1.5435	LearningRate 0.000039
[Ep 108 it 29	 PSNR SIDD: 18.8346	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 108 it 59	 PSNR SIDD: 18.4475	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 108 it 89	 PSNR SIDD: 18.8114	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 108 it 119	 PSNR SIDD: 18.7360	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
Epoch: 108	Time: 26.0461	Loss: 1.5492	LearningRate 0.000037
[Ep 109 it 29	 PSNR SIDD: 18.7758	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 109 it 59	 PSNR SIDD: 18.7987	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 109 it 89	 PSNR SIDD: 18.9926	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 109 it 119	 PSNR SIDD: 18.8430	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
Epoch: 109	Time: 25.1575	Loss: 1.4853	LearningRate 0.000035
[Ep 110 it 29	 PSNR SIDD: 19.0717	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 110 it 59	 PSNR SIDD: 18.8496	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 110 it 89	 PSNR SIDD: 18.9568	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
[Ep 110 it 119	 PSNR SIDD: 18.8274	] ----  [best_Ep_SIDD 95 best_it_SIDD 119 Best_PSNR_SIDD 19.1867] 
Epoch: 110	Time: 25.8434	Loss: 1.5055	LearningRate 0.000034
[Ep 111 it 29	 PSNR SIDD: 19.2872	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 111 it 59	 PSNR SIDD: 18.7855	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 111 it 89	 PSNR SIDD: 18.5404	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 111 it 119	 PSNR SIDD: 18.6859	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 111	Time: 26.0411	Loss: 1.5114	LearningRate 0.000032
[Ep 112 it 29	 PSNR SIDD: 18.7978	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 112 it 59	 PSNR SIDD: 18.6918	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 112 it 89	 PSNR SIDD: 18.8505	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 112 it 119	 PSNR SIDD: 18.9132	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 112	Time: 25.7787	Loss: 1.4392	LearningRate 0.000031
[Ep 113 it 29	 PSNR SIDD: 18.7174	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 113 it 59	 PSNR SIDD: 18.5827	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 113 it 89	 PSNR SIDD: 18.5994	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 113 it 119	 PSNR SIDD: 18.8881	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 113	Time: 26.1213	Loss: 1.4824	LearningRate 0.000029
[Ep 114 it 29	 PSNR SIDD: 18.7168	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 114 it 59	 PSNR SIDD: 18.7026	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 114 it 89	 PSNR SIDD: 18.6862	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 114 it 119	 PSNR SIDD: 19.1759	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 114	Time: 26.2936	Loss: 1.5421	LearningRate 0.000028
[Ep 115 it 29	 PSNR SIDD: 18.6245	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 115 it 59	 PSNR SIDD: 18.8561	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 115 it 89	 PSNR SIDD: 18.9456	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 115 it 119	 PSNR SIDD: 18.9903	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 115	Time: 26.1329	Loss: 1.4553	LearningRate 0.000026
[Ep 116 it 29	 PSNR SIDD: 19.0367	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 116 it 59	 PSNR SIDD: 18.7171	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 116 it 89	 PSNR SIDD: 18.8604	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 116 it 119	 PSNR SIDD: 19.1558	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 116	Time: 26.4371	Loss: 1.4844	LearningRate 0.000025
[Ep 117 it 29	 PSNR SIDD: 18.8035	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 117 it 59	 PSNR SIDD: 18.9000	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 117 it 89	 PSNR SIDD: 18.8233	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 117 it 119	 PSNR SIDD: 18.9229	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 117	Time: 26.5928	Loss: 1.4538	LearningRate 0.000023
[Ep 118 it 29	 PSNR SIDD: 18.8278	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 118 it 59	 PSNR SIDD: 18.8826	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 118 it 89	 PSNR SIDD: 18.8930	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 118 it 119	 PSNR SIDD: 18.9656	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 118	Time: 24.7001	Loss: 1.4830	LearningRate 0.000022
[Ep 119 it 29	 PSNR SIDD: 18.9442	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 119 it 59	 PSNR SIDD: 18.9725	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 119 it 89	 PSNR SIDD: 18.8914	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 119 it 119	 PSNR SIDD: 18.8340	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 119	Time: 25.6118	Loss: 1.5027	LearningRate 0.000021
[Ep 120 it 29	 PSNR SIDD: 18.9222	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 120 it 59	 PSNR SIDD: 18.6240	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 120 it 89	 PSNR SIDD: 18.7369	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 120 it 119	 PSNR SIDD: 18.8585	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 120	Time: 25.1893	Loss: 1.4893	LearningRate 0.000020
[Ep 121 it 29	 PSNR SIDD: 18.6747	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 121 it 59	 PSNR SIDD: 18.8771	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 121 it 89	 PSNR SIDD: 18.9745	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 121 it 119	 PSNR SIDD: 18.8635	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 121	Time: 25.2515	Loss: 1.5109	LearningRate 0.000018
[Ep 122 it 29	 PSNR SIDD: 18.7621	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 122 it 59	 PSNR SIDD: 18.8928	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 122 it 89	 PSNR SIDD: 18.8453	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 122 it 119	 PSNR SIDD: 19.0286	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 122	Time: 25.3283	Loss: 1.5004	LearningRate 0.000017
[Ep 123 it 29	 PSNR SIDD: 18.9415	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 123 it 59	 PSNR SIDD: 18.7650	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 123 it 89	 PSNR SIDD: 18.8532	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 123 it 119	 PSNR SIDD: 18.8405	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 123	Time: 25.1400	Loss: 1.4398	LearningRate 0.000016
[Ep 124 it 29	 PSNR SIDD: 18.7069	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 124 it 59	 PSNR SIDD: 18.9157	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 124 it 89	 PSNR SIDD: 18.8539	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 124 it 119	 PSNR SIDD: 19.0202	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 124	Time: 25.0309	Loss: 1.4379	LearningRate 0.000015
[Ep 125 it 29	 PSNR SIDD: 18.9150	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 125 it 59	 PSNR SIDD: 18.6049	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 125 it 89	 PSNR SIDD: 18.9779	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 125 it 119	 PSNR SIDD: 19.0630	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 125	Time: 25.3857	Loss: 1.4599	LearningRate 0.000014
[Ep 126 it 29	 PSNR SIDD: 18.9066	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 126 it 59	 PSNR SIDD: 18.9671	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 126 it 89	 PSNR SIDD: 18.9292	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 126 it 119	 PSNR SIDD: 18.9507	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 126	Time: 24.9580	Loss: 1.4001	LearningRate 0.000013
[Ep 127 it 29	 PSNR SIDD: 18.8370	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 127 it 59	 PSNR SIDD: 18.8809	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 127 it 89	 PSNR SIDD: 18.9825	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 127 it 119	 PSNR SIDD: 18.9509	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 127	Time: 24.7104	Loss: 1.4428	LearningRate 0.000012
[Ep 128 it 29	 PSNR SIDD: 18.8854	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 128 it 59	 PSNR SIDD: 19.0216	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 128 it 89	 PSNR SIDD: 19.0606	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 128 it 119	 PSNR SIDD: 18.6810	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 128	Time: 26.3993	Loss: 1.4161	LearningRate 0.000011
[Ep 129 it 29	 PSNR SIDD: 18.8152	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 129 it 59	 PSNR SIDD: 18.8542	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 129 it 89	 PSNR SIDD: 18.9921	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 129 it 119	 PSNR SIDD: 18.8187	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 129	Time: 26.0915	Loss: 1.4752	LearningRate 0.000010
[Ep 130 it 29	 PSNR SIDD: 18.7323	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 130 it 59	 PSNR SIDD: 18.6878	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 130 it 89	 PSNR SIDD: 18.9398	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 130 it 119	 PSNR SIDD: 18.8660	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 130	Time: 25.5961	Loss: 1.4549	LearningRate 0.000009
[Ep 131 it 29	 PSNR SIDD: 18.7710	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 131 it 59	 PSNR SIDD: 18.7269	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 131 it 89	 PSNR SIDD: 18.7002	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 131 it 119	 PSNR SIDD: 18.7541	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 131	Time: 26.2561	Loss: 1.4364	LearningRate 0.000008
[Ep 132 it 29	 PSNR SIDD: 18.9153	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 132 it 59	 PSNR SIDD: 18.7525	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 132 it 89	 PSNR SIDD: 18.8253	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 132 it 119	 PSNR SIDD: 18.7218	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 132	Time: 26.1157	Loss: 1.5009	LearningRate 0.000008
[Ep 133 it 29	 PSNR SIDD: 18.9701	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 133 it 59	 PSNR SIDD: 18.8776	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 133 it 89	 PSNR SIDD: 18.9240	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 133 it 119	 PSNR SIDD: 18.9273	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 133	Time: 24.6351	Loss: 1.4612	LearningRate 0.000007
[Ep 134 it 29	 PSNR SIDD: 18.8664	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 134 it 59	 PSNR SIDD: 18.8343	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 134 it 89	 PSNR SIDD: 18.7221	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 134 it 119	 PSNR SIDD: 18.7612	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 134	Time: 25.0470	Loss: 1.4365	LearningRate 0.000006
[Ep 135 it 29	 PSNR SIDD: 18.9454	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 135 it 59	 PSNR SIDD: 18.7084	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 135 it 89	 PSNR SIDD: 18.9278	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 135 it 119	 PSNR SIDD: 18.9522	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 135	Time: 24.0100	Loss: 1.4159	LearningRate 0.000005
[Ep 136 it 29	 PSNR SIDD: 18.6924	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 136 it 59	 PSNR SIDD: 18.7749	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 136 it 89	 PSNR SIDD: 18.9659	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 136 it 119	 PSNR SIDD: 18.9485	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 136	Time: 26.0244	Loss: 1.4502	LearningRate 0.000005
[Ep 137 it 29	 PSNR SIDD: 18.8867	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 137 it 59	 PSNR SIDD: 18.9339	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 137 it 89	 PSNR SIDD: 18.9153	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 137 it 119	 PSNR SIDD: 18.9618	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 137	Time: 26.6421	Loss: 1.4135	LearningRate 0.000004
[Ep 138 it 29	 PSNR SIDD: 18.7911	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 138 it 59	 PSNR SIDD: 18.9248	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 138 it 89	 PSNR SIDD: 18.8424	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 138 it 119	 PSNR SIDD: 18.9388	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 138	Time: 25.9296	Loss: 1.4357	LearningRate 0.000004
[Ep 139 it 29	 PSNR SIDD: 18.9703	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 139 it 59	 PSNR SIDD: 18.9029	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 139 it 89	 PSNR SIDD: 18.9136	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 139 it 119	 PSNR SIDD: 18.8807	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 139	Time: 24.5787	Loss: 1.4177	LearningRate 0.000003
[Ep 140 it 29	 PSNR SIDD: 18.8241	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 140 it 59	 PSNR SIDD: 18.8633	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 140 it 89	 PSNR SIDD: 18.8654	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 140 it 119	 PSNR SIDD: 18.9288	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 140	Time: 24.8463	Loss: 1.4023	LearningRate 0.000003
[Ep 141 it 29	 PSNR SIDD: 18.8905	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 141 it 59	 PSNR SIDD: 18.9297	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 141 it 89	 PSNR SIDD: 18.8947	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 141 it 119	 PSNR SIDD: 18.8923	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 141	Time: 24.5413	Loss: 1.4437	LearningRate 0.000002
[Ep 142 it 29	 PSNR SIDD: 18.8589	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 142 it 59	 PSNR SIDD: 18.8981	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 142 it 89	 PSNR SIDD: 18.8613	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 142 it 119	 PSNR SIDD: 18.8321	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 142	Time: 26.8266	Loss: 1.5195	LearningRate 0.000002
[Ep 143 it 29	 PSNR SIDD: 18.9250	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 143 it 59	 PSNR SIDD: 18.9046	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 143 it 89	 PSNR SIDD: 18.9534	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 143 it 119	 PSNR SIDD: 18.9043	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 143	Time: 25.5246	Loss: 1.4124	LearningRate 0.000002
[Ep 144 it 29	 PSNR SIDD: 18.9799	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 144 it 59	 PSNR SIDD: 18.9676	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 144 it 89	 PSNR SIDD: 18.9447	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 144 it 119	 PSNR SIDD: 18.9219	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 144	Time: 25.7060	Loss: 1.4441	LearningRate 0.000002
[Ep 145 it 29	 PSNR SIDD: 18.9221	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 145 it 59	 PSNR SIDD: 18.9551	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 145 it 89	 PSNR SIDD: 18.9064	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 145 it 119	 PSNR SIDD: 18.9031	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 145	Time: 25.4410	Loss: 1.4702	LearningRate 0.000001
[Ep 146 it 29	 PSNR SIDD: 18.9428	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 146 it 59	 PSNR SIDD: 18.9199	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 146 it 89	 PSNR SIDD: 18.9060	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 146 it 119	 PSNR SIDD: 18.8481	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 146	Time: 25.8787	Loss: 1.4285	LearningRate 0.000001
[Ep 147 it 29	 PSNR SIDD: 18.8884	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 147 it 59	 PSNR SIDD: 18.8900	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 147 it 89	 PSNR SIDD: 18.9029	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 147 it 119	 PSNR SIDD: 18.9315	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 147	Time: 24.5988	Loss: 1.4097	LearningRate 0.000001
[Ep 148 it 29	 PSNR SIDD: 18.9065	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 148 it 59	 PSNR SIDD: 18.8879	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 148 it 89	 PSNR SIDD: 18.8777	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 148 it 119	 PSNR SIDD: 18.8734	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 148	Time: 25.5626	Loss: 1.4469	LearningRate 0.000001
[Ep 149 it 29	 PSNR SIDD: 18.9093	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 149 it 59	 PSNR SIDD: 18.8940	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 149 it 89	 PSNR SIDD: 18.8625	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 149 it 119	 PSNR SIDD: 18.8908	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 149	Time: 25.6704	Loss: 1.4307	LearningRate 0.000001
[Ep 150 it 29	 PSNR SIDD: 18.8982	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 150 it 59	 PSNR SIDD: 18.8867	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 150 it 89	 PSNR SIDD: 18.8856	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
[Ep 150 it 119	 PSNR SIDD: 18.9010	] ----  [best_Ep_SIDD 111 best_it_SIDD 29 Best_PSNR_SIDD 19.2872] 
Epoch: 150	Time: 25.9040	Loss: 1.4246	LearningRate 0.000001
