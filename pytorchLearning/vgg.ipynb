{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os, glob\n",
    " \n",
    "data_dir = './test'  # train\n",
    "features_dir = './Vgg_features_test'  # Vgg_features_train\n",
    " \n",
    " \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        VGG = models.vgg16(pretrained=True)\n",
    "        self.feature = VGG.features\n",
    "        self.classifier = nn.Sequential(*list(VGG.classifier.children())[:-3])\n",
    "        pretrained_dict = VGG.state_dict()\n",
    "        model_dict = self.classifier.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        self.classifier.load_state_dict(model_dict)\n",
    " \n",
    "    def forward(self, x):\n",
    "        output = self.feature(x)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.classifier(output)\n",
    "        return output\n",
    " \n",
    " \n",
    "model = Encoder()\n",
    "model = model.cuda()\n",
    " \n",
    " \n",
    "def extractor(img_path, saved_path, net, use_gpu):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()]\n",
    "    )\n",
    " \n",
    "    img = Image.open(img_path)\n",
    "    img = transform(img)\n",
    "    print(img.shape)\n",
    " \n",
    "    x = Variable(torch.unsqueeze(img, dim=0).float(), requires_grad=False)\n",
    "    print(x.shape)\n",
    " \n",
    "    if use_gpu:\n",
    "        x = x.cuda()\n",
    "        net = net.cuda()\n",
    "    y = net(x).cpu()\n",
    "    y = torch.squeeze(y)\n",
    "    y = y.data.numpy()\n",
    "    print(y.shape)\n",
    "    np.savetxt(saved_path, y, delimiter=',')\n",
    " \n",
    " \n",
    "extensions = ['jpg', 'jpeg', 'JPG', 'JPEG']\n",
    "\n",
    "files_list = []\n",
    "x = os.walk(data_dir)\n",
    "for path, d, filelist in x:\n",
    "    for filename in filelist:\n",
    "        file_glob = os.path.join(path, filename)\n",
    "        files_list.extend(glob.glob(file_glob))\n",
    "\n",
    "print(files_list)\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "for x_path in files_list:\n",
    "    print(\"x_path\" + x_path)\n",
    "    file_name = x_path.split('/')[-1]\n",
    "    fx_path = os.path.join(features_dir, file_name + '.txt')\n",
    "    print(fx_path)\n",
    "    extractor(x_path, fx_path, model, use_gpu)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['./test/a.png']\n",
      "x_path./test/a.png\n",
      "./Vgg_features_test/a.png.txt\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "(4096,)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('lxj': conda)"
  },
  "interpreter": {
   "hash": "e970e3a089ccae2cd07fccc4512d6742f9f9435469c2a9fbd55abc6113d61ae6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}